clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2022 <- read_csv("data/2022Q2.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2022 <- read_csv("data/2022Q1.csv")%>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column
q4_2021 <- read_csv("data/2021Q4.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""
#2 27712    14 15 columns      14 columns ""
# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")
q3_2021 <- read_csv("data/2021Q3.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2021 <- read_csv("data/2021Q2.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column
q1_2021 <- read_csv("data/2021Q1.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2020 <- read_csv("data/2020Q4.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2020 <- read_csv("data/2020Q3.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2020 <- read_csv("data/2020Q2.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2020 <- read_csv("data/2020Q1.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""
# 2 121791    16 a double FISC   ""
# 3 121792    16 a double FISC   ""
# 4 121793    16 a double FISC   ""
# 5 132094    16 a double FISC   ""
# 6 132095    16 a double FISC   ""
# 7 132096    16 a double FISC   ""
# 8 132097    16 a double FISC   ""
# 9 132098    16 a double FISC   ""
#10 132099    16 a double FISC   ""
#11 132100    16 a double FISC   ""
#12 132101    16 a double FISC   ""
#13 132102    16 a double FISC   ""
#14 132103    16 a double FISC   ""
#15 132104    16 a double FISC   ""
#16 132105    16 a double FISC   ""
#17 132106    16 a double FISC   ""
#18 132107    16 a double FISC   ""
#19 132108    16 a double FISC   ""
#20 132109    16 a double FISC   ""
# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?
q4_2019 <- read_csv("data/2019Q4.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2019 <- read_csv("data/2019Q3.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2019 <- read_csv("data/2019Q2.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"
q1_2019 <- read_csv("data/2019Q1.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2018 <- read_csv("data/2018Q4.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2018 <- read_csv("data/2018Q3.csv") %>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 ""
# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")
q2_2018 <- read_csv("data/2018Q2.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2018 <- read_csv("data/2018Q1.csv")%>%
mutate(YEAR = as.numeric("2018")) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Bind dataframes into one combined dataframe
house_spend_18_22 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
# Number of rows is 2,185,315
unique(house_spend_18_22$sort_sequence)
house_spend_18_22 <- house_spend_18_22 %>%
mutate(office_year = as.numeric(sub(".*?(\\d{4}).*", "\\1", house_spend_18_22$office)))
glimpse(house_spend_18_22)
# Install necessary packages (remove # if libraries are needed)
#remotes::install_github("mkearney/dapr")
#remotes::install_github("mkearney/tfse")
#remotes::install_github("mkearney/ppcong")
# Load ppcong library
library(ppcong)
## Save API key for use in ppcong. Data in parentheses can be replaced by another individual API key.
ppc_api_key("yosRYPlksfSYRNTfhgot3bNTzvYQNZ8ztredZ7da", set_renv = TRUE) #this is Aya's api key
# Bring in information on House members for the 115th, 116th and 117th congresses, which cover from January 2017 to January 2023, as our expenditure dataset covers 2018 to 2022.
h115 <- ppc_members(congress = "115", chamber = "house")
h116 <- ppc_members(congress = "116", chamber = "house")
h117 <- ppc_members(congress = "117", chamber = "house")
# Bind dataframes from the three Congresses
members_18_22 <- bind_rows(list(h115, h116, h117))
# Select the columns that we need and then get rid of any duplicates
cleaned_members_18_22 <- members_18_22 |>
select(id, first_name, last_name, gender, party, state, district) |>
distinct()|>
mutate(first_name = str_to_upper(first_name))|>
mutate(last_name = str_to_upper(last_name))
# Join the member information with our expenses dataset using the bioguide id
spend_with_member_info <- house_spend_18_22 |>
left_join(cleaned_members_18_22, by = c("bioguide_id" = "id"))
cleaned_members_18_22 %>%
group_by(id) %>%
summarise(instances = n()) %>%
arrange(desc(instances))
recleaned_members_18_22 <- members_18_22 |>
select(id, first_name, last_name, gender, party, state) |>
distinct()|>
mutate(first_name = str_to_upper(first_name))|>
mutate(last_name = str_to_upper(last_name))
recleaned_members_18_22 %>%
group_by(id) %>%
summarise(instances = n()) %>%
arrange(desc(instances))
# Join the member information with our expenses data set using the bioguide id. Also add a step so we're only looking at DMV representatives.
dmv_spend_with_member_info <- house_spend_18_22 |>
left_join(recleaned_members_18_22, by = c("bioguide_id" = "id")) |>
filter(state == "DC" | state == "VA" | state == "MD")
# create a dmv_df that's only the subtotals
totals_dmv_spend <- dmv_spend_with_member_info %>%
filter(sort_sequence == "SUBTOTAL") %>%
select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -payee, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)
# do the same thing for house_spend_18_22, which we will also use later.
house_spend_18_22 <- house_spend_18_22 %>%
filter(sort_sequence == "SUBTOTAL") %>%
select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -payee, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)
# write the dataframes to csv in order to skip the cleaning process moving forward
write_csv(spend_with_member_info, "data/spend_with_member_info.csv")
write_csv(dmv_spend_with_member_info, "data/dmv_spend_with_member_info.csv")
write_csv(totals_dmv_spend, "data/totals_dmv_spend.csv")
write_csv(house_spend_18_22, "data/house_spend_18_22.csv")
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Load the data from ProPublica.
# In the sort_sequence row, we will ONLY be using "SUBTOTAL" rows, filtering out specific expenses (DETAIL) and GRAND TOTAL FOR ORGANIZATION so that the dataset is small enough to be agile and does not have redundancies that will adversely impact the math we're looking to do.
# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011
# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.
# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").
# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.
# Cleaned datatypes in columns one-by-one while exploring the distinct issues across different quarters. We will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, and q3_2018.
q4_2022 <- read_csv("data/2022Q4.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4")) %>%
rename(start_date = perform_start_dt,
end_date = perform_end_dt)
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Load the data from ProPublica.
# In the sort_sequence row, we will ONLY be using "SUBTOTAL" rows, filtering out specific expenses (DETAIL) and GRAND TOTAL FOR ORGANIZATION so that the dataset is small enough to be agile and does not have redundancies that will adversely impact the math we're looking to do.
# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011
# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.
# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").
# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.
# Cleaned datatypes in columns one-by-one while exploring the distinct issues across different quarters. We will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, and q3_2018.
q4_2022 <- read_csv("data/2022Q4.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4")) %>%
rename(start_date = perform_start_dt,
end_date = perform_end_dt)
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Begin by reading in the four dataframes that were created in "clean_only.rmd"
# Spend_with_member_info.csv is too large to push via GitHub, please see WeTransfer and drop into data folder for this repository on desktop.
spend_with_member_info <- read_csv("data/spend_with_member_info.csv")
dmv_spend_with_member_info <- read_csv("data/dmv_spend_with_member_info.csv")
house_spend_18_22 <- read_csv("data/house_spend_18_22.csv")
totals_dmv_spend <- read_csv("data/totals_dmv_spend.csv")
# Let's look at the spending categories (column is called purpose) to get a general sense of where reps are using their budgets.
totals_dmv_spend_purpose <- totals_dmv_spend %>%
group_by(purpose) %>%
summarise(total_expenses = sum(amount)) %>%
arrange(desc(total_expenses))
totals_dmv_spend_purpose
# OFFICIAL EXPENSES OF MEMBER TOTALS sounds really vague, and it's the top category by far with a spend of $135,333,002.69. We also notice that Official Expenses of Members is one of the two options for the "program" column in totals_dmv_spend. That seems like a red flag.
# The other value in the program column is INTERN ALLOWANCES. We have a column in totals_dmv_spend_purpose called INTERN ALLOWANCES TOTALS: as well, which totals $1,532,417.41
# Are these two values in the purpose category redundant? Let's save these numbers, then filter the two rows out and see if they equal the sum of all other purposes that remain.
official <- 135333002.69
interns <- 1532417.41
totals_dmv_spend_purpose <- totals_dmv_spend %>%
filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|>
filter(purpose != "INTERN ALLOWANCES TOTALS:")|>
group_by(purpose) %>%
summarise(total_expenses = sum(amount)) %>%
arrange(desc(total_expenses))
totals_dmv_spend_purpose
# What's the sum of all of the remaining 9 categories? Does it equal the sum of OFFICIAL EXPENSES OF MEMBER TOTALS and INTERN ALLOWANCES?
without_official_interns <- sum(totals_dmv_spend_purpose$total_expenses)
remainder <- (without_official_interns - official - interns)
remainder
# We have an extremely small decimal here that would have been rounded to zero for accounting purposes. So that appears to be a total redundancy after all.
# Let's resave totals_dmv_spend so that we are permanently excluding these redundancies when working with that dataframe.
totals_dmv_spend <- totals_dmv_spend %>%
filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|>
filter(purpose != "INTERN ALLOWANCES TOTALS:")
# Just double checking that now we have only the appropriate 9 options for purpose.
totals_dmv_spend_purpose <- totals_dmv_spend %>%
group_by(purpose) %>%
summarise(total_expenses = sum(amount)) %>%
arrange(desc(total_expenses))
totals_dmv_spend_purpose
# Let's get a percent of total column as well to get a sense of where reps are spending the most and least across the 9 categories.
totals_dmv_spend_purpose <- totals_dmv_spend_purpose |>
mutate(pct_of_total = (total_expenses/(sum(total_expenses)))*100)
# We need to look at the overall house spend but first let's rid it of the redundancies we found above with Official Member Expenses and Intern Allowance.
house_spend_18_22 <- house_spend_18_22 |>
filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|>
filter(purpose != "INTERN ALLOWANCES TOTALS:")
house_spend_18_22
# Calculate average spend for all members, not just those in the DMV. First, filter out non-member offices and committees to confirm that there are 435 unique members per year.
house_spend_18_22 <- house_spend_18_22 %>%
filter(!is.na(bioguide_id))
house_spend_18_22 %>%
filter(office_year >= 2018) %>%
group_by(office_year, bioguide_id) %>%
summarise() %>%
group_by(office_year) %>%
summarise(count = n())
# Surprisingly, there are more than 435 members each year even after we've filtered out records without a bioguide_id and by the office_year (which is intended to avoid any confusion about offices changing hands in January). But we do know that sometimes reps pass away, are appointed to other positions, or leave their seats for other reasons and are replaced. So we'll need to divide by the numbers above to find our average rather than 435 for every year.
house_spend_18_22_totals <- house_spend_18_22 %>%
group_by(year) %>%
summarise(annual_total = sum(amount)) %>%
mutate(members_per_year = c(451, 447, 442, 451, 448)) %>%
mutate(annual_avg_per_member = annual_total / members_per_year)
house_spend_18_22_totals
# Now do the same process for DMV reps.
totals_dmv_spend %>%
filter(office_year >= 2018) %>%
group_by(office_year, bioguide_id) %>%
summarise() %>%
group_by(office_year) %>%
summarise(count = n())
totals_dmv_spend_totals <- totals_dmv_spend %>%
group_by(year) %>%
summarise(dmv_annual_total = sum(amount)) %>%
mutate(dmv_annual_avg_per_member = dmv_annual_total / 20)
totals_dmv_spend_totals
# Now join to compare side by side.
house_dmv_totals <- house_spend_18_22_totals |>
left_join(totals_dmv_spend_totals, join_by(year))
house_dmv_totals
house_dmv_totals <- house_dmv_totals |>
group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|>
summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)
average_total_difference <- mean(house_dmv_totals$difference)
average_total_difference
# So on average, DMV reps spent less every year than the House as a whole did, on average $15,254.09 less per member each year.
# Now let's test the hypothesis that DMV reps probably spend less on transportation than other members do.
house_spend_18_22_travel <- house_spend_18_22 %>%
filter(purpose == "TRAVEL TOTALS:") %>%
#need to group_by and calculate avgs per year so our avgs aren't skewed based on how many years a member has served
group_by(year) %>%
summarise(annual_total = sum(amount)) %>%
mutate(members_per_year = c(451, 447, 442, 451, 448)) %>%
mutate(annual_avg_per_member = annual_total / members_per_year)
house_spend_18_22_travel
dmv_spend_travel <- totals_dmv_spend %>%
filter(purpose == "TRAVEL TOTALS:") %>%
#need to group_by and calculate avgs per year so our avgs aren't skewed based on how many years a member has served
group_by(year) %>%
summarise(dmv_annual_total = sum(amount)) %>%
mutate(dmv_annual_avg_per_member = dmv_annual_total / 20)
dmv_spend_travel
house_dmv_travel <- house_spend_18_22_travel |>
left_join(dmv_spend_travel, join_by(year))
house_dmv_travel
house_dmv_travel<- house_dmv_travel |>
group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|>
summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)
house_dmv_travel
average_difference <- mean(house_dmv_travel$difference)
average_difference
# Hypothesis confirmed that they spend substantially less on travel than other members, on average more $32,870.38 less annually per member. But they only spend ~$15.2K less than others overall, meaning that they are overspending somewhere else.
# Let's look at spending by category to figure out where DMV reps are actually outspending their colleagues. Because we already have totals_dmv_spend_purpose, we'll create an analogous df for the house to compare spending by percent allocation across the 9 categories.
house_spend_18_22_purpose <- house_spend_18_22 %>%
group_by(purpose) %>%
summarise(house_total_expenses = sum(amount)) %>%
arrange(desc(house_total_expenses))|>
mutate(house_pct_of_total = (house_total_expenses/(sum(house_total_expenses)))*100)
totals_dmv_spend_purpose <- totals_dmv_spend_purpose |>
rename(dmv_total_expenses = total_expenses)|>
rename(dmv_pct_of_total = pct_of_total)
# Join to compare side by side.
category_comparison <- house_spend_18_22_purpose |>
left_join(totals_dmv_spend_purpose, join_by(purpose))
# Add a column that shows the percent difference between DMV rep and overall rep spending across the categories.
category_comparison <- category_comparison |>
mutate(dmv_difference = dmv_pct_of_total - house_pct_of_total)
# First we needed to do a little research about who controlled the House from 2018-2022. It was Republicans in 2018 and Democrats every other year, so we made a simple spreadsheet to import.
house_majority <- read_csv("data/house_majority.csv")
# Join with the totals_dmv_spend dataframe
totals_dmv_spend <- totals_dmv_spend |>
left_join(house_majority, join_by("office_year" == "year"))
totals_dmv_spend
# Look at spending by party each year.
totals_dmv_spend |>
filter(office_year >= 2018)|>
group_by(office_year, party, majority_party)|>
summarise(party_spend = sum(amount))
# Clearly Democrats are way outspending Republicans overall. But is that just because there are most Democrats representing the DMV. We need to look at average spending per member.
# To do that, we have to find the number of members each party had in the DMV each year. We know there are 20 seats total. This will allow us to calculate an average spend by party for each year. First, make a df with one row per member per year, along with their party
all_members_per_year <- totals_dmv_spend %>%
filter(office_year >=2018)  %>%
group_by(office_year,bioguide_id,party) %>%
summarise()
all_members_per_year
# Calculate party members per year.
members_grouped_per_year <- all_members_per_year %>%
group_by(party, office_year) %>%
summarise(party_members_per_year = n()) %>%
arrange(office_year)
members_grouped_per_year
# Calculate how much each party spent per year.
party_spending_annual <- totals_dmv_spend |>
filter(office_year >=2018)  %>%
group_by(party, office_year, majority_party)|>
summarise(party_spend = sum(amount))|>
arrange(desc(party_spend)) %>%
arrange(office_year)
party_spending_annual
# Join the dfs and calculate an average spend per member for each party per year.
party_spending_w_rep_numbers <- party_spending_annual %>%
left_join(members_grouped_per_year) %>%
mutate(avg_spend_per_member = party_spend / party_members_per_year) %>%
arrange(desc(avg_spend_per_member))
party_spending_w_rep_numbers|>
select(-party_spend, -party_members_per_year)|>
arrange(office_year)
# Since there isn't a specific date column, we need to go by year. 2020 and 2021 were the main COVID years.
# We need to look at total spending of each category by year:
category_by_year <- totals_dmv_spend |>
filter(office_year >= 2018, office_year <= 2022)|>
group_by(office_year, purpose) |>
summarize(total_spend = sum(amount)) |>
drop_na()
category_by_year
# It's really hard to compare the amounts by just looking at the table. A visualization would greatly help with comparing the different categories:
category_by_year |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
facet_wrap(~purpose) +
labs(x="Year",
y="Amount Spent")
# Because personnel compensation is so much greater than all other categories, it's throwing off the scale of the visualization. Let's remove it and look at the other 8 categories side by side.
category_by_year |>
filter(purpose != "PERSONNEL COMPENSATION TOTALS:")|>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
facet_wrap(~purpose) +
labs(x="Year",
y="Amount Spent")
# We can also look more closely at all of the 9 categories.
category_by_year |>
filter(purpose == "PERSONNEL COMPENSATION TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="PERSONNEL COMPENSATION",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "EQUIPMENT TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="EQUIPMENT",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "FRANKED MAIL TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="FRANKED MAIL",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "OTHER SERVICES TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="OTHER SERVICES",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "PRINTING AND REPRODUCTION TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="PRINTING AND REPRODUCTION",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "RENT  COMMUNICATION  UTILITIES TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="RENT COMMUNICATION UTILITIES",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "SUPPLIES AND MATERIALS TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="SUPPLIES AND MATERIALS",
caption="source: ProPublica")
category_by_year |>
filter(purpose == "TRAVEL TOTALS:") |>
ggplot() +
geom_line(aes(x=office_year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="TRAVEL",
caption="source: ProPublica")
printing <- spend_with_member_info |>
filter(category == "PRINTING AND REPRODUCTION" & sort_sequence == "DETAIL")
printing_by_year <- printing |>
group_by(year) |>
summarize(total_spend = sum(amount)) |>
mutate(diff_from_previous_year = total_spend - lag(total_spend))
# This shows that there is a $.... increase in spending in printing and reproduction from 2021 to 2022, more than any other year.
printing_by_year |>
ggplot() +
geom_line(aes(x=year, y=total_spend))+
labs(x="Year",
y="Amount Spent",
title="PRINTING AND REPRODUCTION",
caption="source: ProPublica")
# The graph also shows this, proving that this is a Congress-wide trend and not just in the DMV.
View(printing_by_year)
printing_by_office <- printing |>
filter(year == 2022) |>
group_by(first_name, last_name) |>
summarise(spending = sum(amount))
printing_by_purpose <- printing |>
filter(year == 2022) |>
group_by(purpose) |>
summarise(spending = sum(amount))
View(printing_by_office)
View(printing_by_purpose)
View(printing)
printing_nameless_offices <- printing |>
filter(is.na(first_name) & is.na(last_name)) |>
group_by(office) |>
summarise(total_spend = sum(amount))
View(printing_nameless_offices)
