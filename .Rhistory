#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 ""
# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")
q2_2018 <- read_csv("data/2018Q2.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2018 <- read_csv("data/2018Q1.csv")%>%
mutate(YEAR = as.numeric("2018")) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
View(q2_2020)
q1_2018 <- q1_2018 |>
filter(str_detect(sort_sequence, !"TOTAL"))
q1_2018 <- q1_2018 |>
filter(str_detect(sort_sequence != "TOTAL"))
q1_2018 <- q1_2018 |>
filter(sort_sequence != "TOTAL")
q1_2018 <- q1_2018 |>
filter(sort_sequence != "TOTAL")|>
filter(sort_sequence != "SUBTOTAL")|>
filter(sort_sequence != "GRANT TOTAL")
q1_2018 <- q1_2018 |>
filter(sort_sequence != "TOTAL")|>
filter(sort_sequence != "SUBTOTAL")|>
filter(sort_sequence != "GRAND TOTAL")
q1_2018 <- q1_2018 |>
filter(sort_sequence != "TOTAL")|>
filter(sort_sequence != "SUBTOTAL")|>
filter(sort_sequence != "GRAND TOTAL")|>
filter(sort_sequence != "GRAND TOTAL FOR ORGANIZATION")
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Load the data from ProPublica.
# Watch out for "subtotal" rows -- need to filter those out when doing calculations to avoid doubling the real total
# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011
# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.
# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").
# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.
# Cleaned datatypes in columns one-by-one while exploring the distinct issues across different quarters. We will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, q1_2020 and q3_2018.
q4_2022 <- read_csv("data/2022Q4.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4")) %>%
rename(start_date = perform_start_dt,
end_date = perform_end_dt)
q3_2022 <- read_csv("data/2022Q3.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2022 <- read_csv("data/2022Q2.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2022 <- read_csv("data/2022Q1.csv")%>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column
q4_2021 <- read_csv("data/2021Q4.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""
#2 27712    14 15 columns      14 columns ""
# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")
q3_2021 <- read_csv("data/2021Q3.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2021 <- read_csv("data/2021Q2.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column
q1_2021 <- read_csv("data/2021Q1.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2020 <- read_csv("data/2020Q4.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2020 <- read_csv("data/2020Q3.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2020 <- read_csv("data/2020Q2.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2020 <- read_csv("data/2020Q1.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""
# 2 121791    16 a double FISC   ""
# 3 121792    16 a double FISC   ""
# 4 121793    16 a double FISC   ""
# 5 132094    16 a double FISC   ""
# 6 132095    16 a double FISC   ""
# 7 132096    16 a double FISC   ""
# 8 132097    16 a double FISC   ""
# 9 132098    16 a double FISC   ""
#10 132099    16 a double FISC   ""
#11 132100    16 a double FISC   ""
#12 132101    16 a double FISC   ""
#13 132102    16 a double FISC   ""
#14 132103    16 a double FISC   ""
#15 132104    16 a double FISC   ""
#16 132105    16 a double FISC   ""
#17 132106    16 a double FISC   ""
#18 132107    16 a double FISC   ""
#19 132108    16 a double FISC   ""
#20 132109    16 a double FISC   ""
# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?
q4_2019 <- read_csv("data/2019Q4.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2019 <- read_csv("data/2019Q3.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2019 <- read_csv("data/2019Q2.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"
q1_2019 <- read_csv("data/2019Q1.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2018 <- read_csv("data/2018Q4.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2018 <- read_csv("data/2018Q3.csv") %>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 ""
# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")
q2_2018 <- read_csv("data/2018Q2.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2018 <- read_csv("data/2018Q1.csv")%>%
mutate(YEAR = as.numeric("2018")) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Bind dataframes into one combined dataframe
house_spend_18_23 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
View(house_spend_18_23)
house_spend_18_23 <- house_spend_18_23 |>
filter(sort_sequence != "TOTAL")|>
filter(sort_sequence != "SUBTOTAL")|>
filter(sort_sequence != "GRAND TOTAL")|>
filter(sort_sequence != "GRAND TOTAL FOR ORGANIZATION")
house_spend_18_23 |> glimpse()
house_spend_18_23 |> glimpse()|> distint()
house_spend_18_23 |> glimpse()|> distinct()
house_spend_18_23 |>
distinct(sort_sequence)
house_spend_18_23 |>
unique(sort_sequence)
unique(house_spend_18_23$sort_sequence)
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Load the data from ProPublica.
# Watch out for "subtotal" rows -- need to filter those out when doing calculations to avoid doubling the real total
# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011
# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.
# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").
# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.
# Cleaned datatypes in columns one-by-one while exploring the distinct issues across different quarters. We will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, q1_2020 and q3_2018.
q4_2022 <- read_csv("data/2022Q4.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4")) %>%
rename(start_date = perform_start_dt,
end_date = perform_end_dt)
q3_2022 <- read_csv("data/2022Q3.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2022 <- read_csv("data/2022Q2.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2022 <- read_csv("data/2022Q1.csv")%>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column
q4_2021 <- read_csv("data/2021Q4.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""
#2 27712    14 15 columns      14 columns ""
# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")
q3_2021 <- read_csv("data/2021Q3.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2021 <- read_csv("data/2021Q2.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column
q1_2021 <- read_csv("data/2021Q1.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2020 <- read_csv("data/2020Q4.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2020 <- read_csv("data/2020Q3.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2020 <- read_csv("data/2020Q2.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2020 <- read_csv("data/2020Q1.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""
# 2 121791    16 a double FISC   ""
# 3 121792    16 a double FISC   ""
# 4 121793    16 a double FISC   ""
# 5 132094    16 a double FISC   ""
# 6 132095    16 a double FISC   ""
# 7 132096    16 a double FISC   ""
# 8 132097    16 a double FISC   ""
# 9 132098    16 a double FISC   ""
#10 132099    16 a double FISC   ""
#11 132100    16 a double FISC   ""
#12 132101    16 a double FISC   ""
#13 132102    16 a double FISC   ""
#14 132103    16 a double FISC   ""
#15 132104    16 a double FISC   ""
#16 132105    16 a double FISC   ""
#17 132106    16 a double FISC   ""
#18 132107    16 a double FISC   ""
#19 132108    16 a double FISC   ""
#20 132109    16 a double FISC   ""
# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?
q4_2019 <- read_csv("data/2019Q4.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2019 <- read_csv("data/2019Q3.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2019 <- read_csv("data/2019Q2.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"
q1_2019 <- read_csv("data/2019Q1.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2018 <- read_csv("data/2018Q4.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2018 <- read_csv("data/2018Q3.csv") %>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 ""
# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")
q2_2018 <- read_csv("data/2018Q2.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2018 <- read_csv("data/2018Q1.csv")%>%
mutate(YEAR = as.numeric("2018")) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
house_spend_18_23 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
unique(house_spend_18_23$sort_sequence)
house_spend_18_23 <- house_spend_18_23 |>
filter(sort_sequence != "DETAIL")
# Bind dataframes into one combined dataframe
house_spend_18_23 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
# Number of rows is 2,185,315
unique(house_spend_18_23$sort_sequence)
# Filter out all rows that include a specific expense (DETAIL) or a GRAND TOTAL, so that we are only looking at SUBTOTALS per expense category.
house_spend_18_23 <- house_spend_18_23 |>
filter(sort_sequence != "DETAIL")|>
filter(sort_sequence != "GRAND TOTAL FOR ORGANIZATION")
library(ppcong)
## Save API key for use in ppcong. Data in parentheses can be replaced by another individual API key.
ppc_api_key("yosRYPlksfSYRNTfhgot3bNTzvYQNZ8ztredZ7da", set_renv = TRUE) #this is Aya's api key
# Bring in information on House members for the 115th, 116th and 117th congresses, which cover from January 2017 to January 2023, as our expenditure dataset covers 2018 to 2022.
h115 <- ppc_members(congress = "115", chamber = "house")
h116 <- ppc_members(congress = "116", chamber = "house")
h117 <- ppc_members(congress = "117", chamber = "house")
# Bind dataframes from the three Congresses
members_18_22 <- bind_rows(list(h115, h116, h117))
# Select the columns that we need and then get rid of any duplicates
cleaned_members_18_22 <- members_18_22 |>
select(id, first_name, last_name, gender, party, state, district) |>
distinct()|>
mutate(first_name = str_to_upper(first_name))|>
mutate(last_name = str_to_upper(last_name))
# Join the member information with our expenses dataset using the bioguide id
spend_with_member_info <- house_spend_18_23 |>
left_join(cleaned_members_18_22, by = c("bioguide_id" = "id"))
knitr::opts_chunk$set(echo = TRUE)
totals_dmv_spend |>
group_by(party, year, majority_party)|>
summarise(party_spend = sum(amount))|>
arrange(desc(party_spend))
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
totals_dmv_spend |>
group_by(party, year, majority_party)|>
summarise(party_spend = sum(amount))|>
arrange(desc(party_spend))
# Read in the data for spending of DMV reps.
totals_dmv_spend <- read_csv("data/totals_dmv_spend.csv")
# Let's look at the spending categories (column is called purpose) to get a general sense of where reps are using their budgets.
totals_dmv_spend_purpose <- totals_dmv_spend %>%
group_by(purpose) %>%
summarise(total_expenses = sum(amount)) %>%
arrange(desc(total_expenses))
# OFFICIAL EXPENSES OF MEMBER TOTALS sounds really vague, and it's the top number by far with a spend of $135,333,002.69. We also notice that Official Expenses of Members is one of the two options for the program column in totals_dmv_spend. That seems like a red flag.
# The other value in the program column is INTERN ALLOWANCES. We have a column in totals_dmv_spend_purpose called INTERN ALLOWANCES TOTALS: as well, which totals 1532417.41
# Are these two values in the purpose category totally redundant? Let's save these numbers, then filter the two rows out and see if they equal the sum of all other purposes that remain.
official <- 135333002.69
interns <- 1532417.41
totals_dmv_spend_purpose <- totals_dmv_spend %>%
filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|>
filter(purpose != "INTERN ALLOWANCES TOTALS:")|>
group_by(purpose) %>%
summarise(total_expenses = sum(amount)) %>%
arrange(desc(total_expenses))
# What's the sum of all of the remaining 9 categories? Does it equal the sum of OFFICIAL EXPENSES OF MEMBER TOTALS and INTERN ALLOWANCES?
totals_dmv_spend_purpose |>
summarise(total = sum(total_expenses))
without_official_interns <- 136865420
remainder <- (without_official_interns - official - interns)
remainder
# I am not sure why we have $0.10 left over. Upon manually checking the math for the without_official_interns figure, it was actually #136,865,420.10. So we're good!
# Let's make this same change in the totals_dmv_spend so that we are permanently excluding these redundancies when working with that dataframe.
totals_dmv_spend <- totals_dmv_spend %>%
filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|>
filter(purpose != "INTERN ALLOWANCES TOTALS:")
# Just double checking that now we have only the appropriate 9 options for purpose.
totals_dmv_spend %>%
group_by(purpose)|>
summarise()
# Good to go!
# What are the top individual expenses in our data?
totals_dmv_spend |>
group_by(last_name, first_name, purpose, amount)|>
arrange(desc(amount))
# We already know from our category overview that personnel compensation makes up the lion's share of spending by congress. The top expense is from Elaine G. Luria, a Democrat from Virginia, in 2022. Someone in her office made $573,977.80. HOLY SMOKES. That's a pretty penny and might be a story all by itself. Donald McEachin, another dem from VA, also paid a staff member more than half a million dollars last year. Shame on them! I'd guess this would be for Chief of Staff positions, but that needs to be verified.
# First we needed to do a little research about who controlled the House from 2018-2022. It was Republicans in 2018 and Democrats every other year, so we made a simple spreadsheet to import. Let's do that now.
house_majority <- read_csv("data/house_majority.csv")
# Join with the totals_dmv_spend dataframe
totals_dmv_spend <- totals_dmv_spend |>
left_join(house_majority, join_by(year))
# Which political party in the DMV does the most spending? does that change with whether or not that party holds the majority in the House?
totals_dmv_spend |>
group_by(party, year, majority_party)|>
summarise(party_spend = sum(amount))|>
arrange(desc(party_spend))
# Aha! So it looks like Democrats are generally spending more every year, with the exception of 2020 which may be an outlier for many reasons. But Republicans spend the most in 2018, the year they were in the majority.
#
# Are there more Dems or Reps over the 5 years?
totals_dmv_spend |>
group_by(bioguide_id, party, last_name, first_name) |>
summarise() |>
filter(party == "D")
totals_dmv_spend |>
group_by(bioguide_id, party, last_name, first_name) |>
summarise() |>
filter(party == "R")
# There have been 17 Democrats representing the DMV over the past 5 years, in addition to 11 Republicans.
totals_dmv_spend |>
group_by(office, party)|>
summarise(count = n())|>
arrange(office)
totals_dmv_spend |>
group_by(party, year, majority_party)|>
summarise(party_spend = sum(amount))|>
arrange(desc(party_spend))
totals_dmv_spend |>
group_by(party, year, majority_party)|>
summarise(party_spend = sum(amount))|>
arrange(desc(party_spend))
totals_dmv_spend |>
group_by(office, party)|>
summarise(count = n())|>
arrange(office)
totals_dmv_spend |>
group_by(bioguide_id, party, last_name, first_name, year, majority_party)
totals_dmv_spend |>
group_by(bioguide_id, party, last_name, first_name, year, majority_party)
totals_dmv_spend |>
group_by(party, year, majority_party)
totals_dmv_spend |>
group_by(office, party, year)
totals_dmv_spend |>
group_by(party)|>
summarise(county = n())
totals_dmv_spend |>
group_by(party)|>
summarise(count = n())
totals_dmv_spend |>
group_by(party, bioguide_id, year)|>
summarise(count = n())
totals_dmv_spend |>
group_by(bioguide_id, party, year)|>
summarise(count = n())
totals_dmv_spend |>
group_by(bioguide_id, party, year)|>
summarise()
totals_dmv_spend |>
group_by(bioguide_id, party, last_name, first_name) |>
summarise() |>
filter(party == "R")
totals_dmv_spend |>
group_by(bioguide_id, party, year)|>
summarise()
totals_dmv_spend |>
group_by(year, party)|>
summarise()
totals_dmv_spend |>
group_by(year, party, bioguide_id)|>
summarise()
totals_dmv_spend |>
filter(year == 2018)
group_by(party, bioguide_id)
totals_dmv_spend |>
filter(year == 2018)
totals_dmv_spend |>
filter(year == 2018)|>
group_by(party, bioguide_id)
totals_dmv_spend |>
filter(year == 2018)|>
group_by(year, party, bioguide_id)
totals_dmv_spend |>
group_by(office, last_name, first_name, purpose, amount)|>
arrange(amount)
totals_dmv_spend |>
group_by(office)|>
arrange(amount)
totals_dmv_spend <- totals_dmv_spend |>
group_by(office, year)|>
mutate(office_total = sum(amount))
totals_dmv_spend |>
group_by(office)|>
arrange(office_total)
totals_dmv_spend |>
group_by(office, year, office_total)|>
arrange(office_total)
