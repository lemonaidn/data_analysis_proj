geography = "zcta",
variables = c(adult = "B09021_001"),
year = 2021
)
over18_mdzip <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2021
)
over18_mdzip <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_mdzip
over18_moco <- left_join(over18_mdzip, join_by(zip == GEOID))
over18_mdzip
over18_mdzip |> rename(estimate = number_of_adults)
over18_mdzip
over18_mdzip |> rename(estimate = number_of_adults)
over18_mdzip |> rename(number_of_adults = estimate)
View(calls_per_zip)
over18_moco <- left_join(calls_per_zip, join_by(zip == GEOID))
over18acs_mdzip <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18acs_mdzip
over18_mdzip |> rename(number_of_adults = estimate)
calls_per_zip
calls_per_zip |> as.character(zip)
calls_per_zip
over18_moco <- over18_mdzip |> left_join(calls_per_zip, join_by(zip == GEOID))
calls_per_zip
calls_per_zip$zip <- as.character(calls_per_zip$zip)
calls_per_zip
over18_moco <- over18_mdzip |> left_join(calls_per_zip, join_by(zip == GEOID))
over18_moco <- over18_mdzip |> left_join(calls_per_zip, join_by(GEOID == zip))
View(over18_moco)
over18_moco <- get_acs(
geography = "zcta",
state = "MD",
county = "Montgomery",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_moco <- get_acs(
geography = "zcta",
state = "MD",
county = "Montgomery County",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_moco <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_moco
#Part 2
calls_per_zip <- overdose |>
group_by(zip) |>
summarize(number_of_calls = n())
calls_per_zip
#Parts 3 and 4
over18_md <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_md
#Part 5
over18_mdzip |> rename(number_of_adults = estimate)
calls_per_zip$zip <- as.character(calls_per_zip$zip)
calls_per_zip
over18_moco <- over18_md |> left_join(calls_per_zip, join_by(GEOID == zip))
over18_moco
#Part 6
View(over18_moco)
over18_moco <- over18_md |> left_join(calls_per_zip, join_by(GEOID == zip)) |> drop_na()
View(over18_moco)
#Part 2
calls_per_zip <- overdose |>
group_by(zip) |>
summarize(number_of_calls = n())
calls_per_zip
#Parts 3 and 4
over18_md <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_md
#Part 5
over18_mdzip |> rename(number_of_adults = estimate)
calls_per_zip$zip <- as.character(calls_per_zip$zip)
calls_per_zip
over18_moco <- over18_md |> left_join(calls_per_zip, join_by(GEOID == zip)) |> drop_na()
over18_moco
#Part 6
View(over18_moco)
#Part 2
calls_per_zip <- overdose |>
group_by(zip) |>
summarize(number_of_calls = n())
calls_per_zip
#Parts 3 and 4
over18_md <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_md
#Part 5
over18_md |> rename(number_of_adults = estimate)
calls_per_zip$zip <- as.character(calls_per_zip$zip)
calls_per_zip
over18_moco <- over18_md |> left_join(calls_per_zip, join_by(GEOID == zip)) |> drop_na()
over18_moco
#Part 6
View(over18_md)
View(over18_moco)
#Part 2
calls_per_zip <- overdose |>
group_by(zip) |>
summarize(number_of_calls = n())
calls_per_zip
#Parts 3 and 4
over18_md <- get_acs(
geography = "zcta",
state = "MD",
variables = c(adult = "B09021_001"),
year = 2019
)
over18_md
#Part 5
calls_per_zip$zip <- as.character(calls_per_zip$zip)
calls_per_zip
over18_moco <- over18_md |> left_join(calls_per_zip, join_by(GEOID == zip)) |> drop_na()
over18_moco |> rename(number_of_adults = estimate)
over18_moco
#Part 6
knitr::opts_chunk$set(echo = TRUE)
install.packages("ppcong")
knitr::opts_chunk$set(echo = TRUE)
install.packages("ppcong")
# install.packages("remotes")
remotes::install_github("mkearney/ppcong")
library(ppcong)
install.packages(ppcong)
install.packages("ppcong")
knitr::opts_chunk$set(echo = TRUE)
install.packages("ppcong")
# install.packages("remotes")
remotes::install_github("mkearney/ppcong")
library(ppcong)
library(remotes)
install.packages(c("askpass", "credentials", "dplyr", "evaluate", "gert", "ggplot2", "ggwordcloud", "htmltools", "httpuv", "httr2", "knitr", "lattice", "leaflet", "leaflet.providers", "lubridate", "markdown", "Matrix", "matrixStats", "openssl", "pkgload", "plotly", "prettyunits", "ragg", "raster", "RcppArmadillo", "refinr", "reticulate", "rmarkdown", "rprojroot", "RSQLite", "shiny", "sp", "stringi", "stringr", "systemfonts", "terra", "testthat", "text2vec", "textshaping", "tinytex", "vroom", "waldo", "withr", "xfun"))
knitr::opts_chunk$set(echo = TRUE)
install.packages("ppcong")
install.packages("ppcong")
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("mkearney/ppcong")
library(ppcong)
devtools::install_github("username/repository_name")
install.packages("devtools")
install.packages("devtools")
library(devtools)
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("mkearney/ppcong")
install.packages("tfse")
install.packages("remotes")
install.packages("remotes")
knitr::opts_chunk$set(echo = TRUE)
remotes::install_github("mkearney/ppcong")
remotes::install_github("mkearney/tfse")
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Load the data from ProPublica.
# Watch out for "subtotal" rows -- need to filter those out when doing calculations to avoid doubling the real total
# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011
# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.
# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").
# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.
# Did the cleaning one-by-one while exploring the distinct issues across different files. Will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, q1_2020 and q3_2018
q4_2022 <- read_csv("data/2022Q4.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4")) %>%
rename(start_date = perform_start_dt,
end_date = perform_end_dt)
q3_2022 <- read_csv("data/2022Q3.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2022 <- read_csv("data/2022Q2.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2022 <- read_csv("data/2022Q1.csv")%>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column
q4_2021 <- read_csv("data/2021Q4.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""
#2 27712    14 15 columns      14 columns ""
# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")
q3_2021 <- read_csv("data/2021Q3.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2021 <- read_csv("data/2021Q2.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column
q1_2021 <- read_csv("data/2021Q1.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2020 <- read_csv("data/2020Q4.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2020 <- read_csv("data/2020Q3.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2020 <- read_csv("data/2020Q2.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2020 <- read_csv("data/2020Q1.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""
# 2 121791    16 a double FISC   ""
# 3 121792    16 a double FISC   ""
# 4 121793    16 a double FISC   ""
# 5 132094    16 a double FISC   ""
# 6 132095    16 a double FISC   ""
# 7 132096    16 a double FISC   ""
# 8 132097    16 a double FISC   ""
# 9 132098    16 a double FISC   ""
#10 132099    16 a double FISC   ""
#11 132100    16 a double FISC   ""
#12 132101    16 a double FISC   ""
#13 132102    16 a double FISC   ""
#14 132103    16 a double FISC   ""
#15 132104    16 a double FISC   ""
#16 132105    16 a double FISC   ""
#17 132106    16 a double FISC   ""
#18 132107    16 a double FISC   ""
#19 132108    16 a double FISC   ""
#20 132109    16 a double FISC   ""
# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?
q4_2019 <- read_csv("data/2019Q4.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2019 <- read_csv("data/2019Q3.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2019 <- read_csv("data/2019Q2.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"
q1_2019 <- read_csv("data/2019Q1.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2018 <- read_csv("data/2018Q4.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2018 <- read_csv("data/2018Q3.csv") %>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 ""
# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")
q2_2018 <- read_csv("data/2018Q2.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2018 <- read_csv("data/2018Q1.csv")%>%
mutate(YEAR = as.numeric("2018")) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Bind dataframes into one combined dataframe
house_spend_18_23 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
View(house_spend_18_23)
View(house_spend_18_23)
View(house_spend_18_23)
library(ppcong)
#get information on House members
h116 <- ppc_members(congress = "116", chamber = "house")
View(h116)
# Bind dataframes into one combined dataframe
house_spend_18_22 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
#get information on House members for the 116th congress
h116 <- ppc_members(congress = "117", chamber = "house")
View(h116)
#get information on House members for the 116th congress
h117 <- ppc_members(congress = "117", chamber = "house")
View(h117)
h115 <- ppc_members(congress = "115", chamber = "house")
h115 <- ppc_members(congress = "115", chamber = "house")
h117 <- ppc_members(congress = "117", chamber = "house")
# Bind dataframes from the three Congresses
members_18_22 <- bind_rows(list(h115, h116, h117))
View(members_18_22)
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation.
options(scipen=999)
# Load libraries.
library(tidyverse)
library(readr)
library(scales)
library(janitor)
# Load the data from ProPublica.
# Watch out for "subtotal" rows -- need to filter those out when doing calculations to avoid doubling the real total
# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011
# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.
# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").
# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.
# Did the cleaning one-by-one while exploring the distinct issues across different files. Will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, q1_2020 and q3_2018
q4_2022 <- read_csv("data/2022Q4.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4")) %>%
rename(start_date = perform_start_dt,
end_date = perform_end_dt)
q3_2022 <- read_csv("data/2022Q3.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2022 <- read_csv("data/2022Q2.csv") %>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2022 <- read_csv("data/2022Q1.csv")%>%
mutate(YEAR = as.numeric(2022)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column
q4_2021 <- read_csv("data/2021Q4.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""
#2 27712    14 15 columns      14 columns ""
# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")
q3_2021 <- read_csv("data/2021Q3.csv") %>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2021 <- read_csv("data/2021Q2.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column
q1_2021 <- read_csv("data/2021Q1.csv")%>%
mutate(YEAR = as.numeric(2021)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2020 <- read_csv("data/2020Q4.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2020 <- read_csv("data/2020Q3.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2020 <- read_csv("data/2020Q2.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2020 <- read_csv("data/2020Q1.csv")%>%
mutate(YEAR = as.numeric(2020)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""
# 2 121791    16 a double FISC   ""
# 3 121792    16 a double FISC   ""
# 4 121793    16 a double FISC   ""
# 5 132094    16 a double FISC   ""
# 6 132095    16 a double FISC   ""
# 7 132096    16 a double FISC   ""
# 8 132097    16 a double FISC   ""
# 9 132098    16 a double FISC   ""
#10 132099    16 a double FISC   ""
#11 132100    16 a double FISC   ""
#12 132101    16 a double FISC   ""
#13 132102    16 a double FISC   ""
#14 132103    16 a double FISC   ""
#15 132104    16 a double FISC   ""
#16 132105    16 a double FISC   ""
#17 132106    16 a double FISC   ""
#18 132107    16 a double FISC   ""
#19 132108    16 a double FISC   ""
#20 132109    16 a double FISC   ""
# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?
q4_2019 <- read_csv("data/2019Q4.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2019 <- read_csv("data/2019Q3.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
q2_2019 <- read_csv("data/2019Q2.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"
q1_2019 <- read_csv("data/2019Q1.csv")%>%
mutate(YEAR = as.numeric(2019)) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
q4_2018 <- read_csv("data/2018Q4.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("4"))
q3_2018 <- read_csv("data/2018Q3.csv") %>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 ""
# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")
q2_2018 <- read_csv("data/2018Q2.csv")%>%
mutate(YEAR = as.numeric(2018)) %>%
clean_names() %>%
mutate(quarter = as.numeric("2"))
q1_2018 <- read_csv("data/2018Q1.csv")%>%
mutate(YEAR = as.numeric("2018")) %>%
clean_names() %>%
mutate(quarter = as.numeric("1"))
# Bind dataframes into one combined dataframe
house_spend_18_22 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))
library(ppcong)
h115 <- ppc_members(congress = "115", chamber = "house")
h116 <- ppc_members(congress = "116", chamber = "house")
h117 <- ppc_members(congress = "117", chamber = "house")
#get information on House members for the 115th, 116th and 117th congresses, which cover from January 2017 to January 2023. This is because our expenses dataset looks at House spend from 2018 to 2022.
h115 <- ppc_members(congress = "115", chamber = "house")
# Bind dataframes from the three Congresses
members_18_22 <- bind_rows(list(h115, h116, h117))
# Select the columns that we need and then get rid of any duplicates
cleaned_members_18_22 <- members_18_22 |>
select(id, first_name, middle_name, last_name, gender, party, state, district) |>
distinct()
#Join the member information with our expenses dataset using the bioguide id
spend_with_member_info <- house_spend_18_22 |>
left_join(cleaned_members_18_22, by = c("bioguide_id" = "id"))
View(spend_with_member_info)
setwd("~/Documents/data_analysis_proj")
spend_with_member_info <- house_spend_18_22 |>
left_join(cleaned_members_18_22, join_by("bioguide_id" = "id"))
spend_with_member_info <- house_spend_18_22 |>
left_join(cleaned_members_18_22, join_by("bioguide_id" == "id"))
spend_with_member_info <- house_spend_18_22 |>
left_join(cleaned_members_18_22, by = c("bioguide_id" = "id"))
View(house_spend_18_22)
View(house_spend_18_22)
