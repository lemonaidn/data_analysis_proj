---
title: "Data Anaylisis Team 3 Notebook"
author: "Aidan Hughes, Aya Hussein, Caley Fox Shannon"
date: "`r Sys.Date()`"
output: html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

For our data analysis project, we have chosen to look at House of Representatives Office Expenditures. We think that the dataset is rich with newsworthy details and we know that the public is generally interested in how lawmakers spend our tax dollars.

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}

# Turn off scientific notation. 

options(scipen=999)

# Load libraries. 

library(tidyverse)
library(readr)
library(scales)
library(janitor)

```

### TO SKIP CLEAN PROCESS AND WORK WITH totals_dmv_spend, use search function to look for "POST-CLEAN" and start there.  

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data. 

```{r}

# Load the data from ProPublica.

# In the sort_sequence row, we will ONLY be using "SUBTOTAL" rows, filtering out specific expenses (DETAIL) and GRAND TOTAL FOR ORGANIZATION so that the dataset is small enough to be agile and does not have redundancies that will adversely impact the math we're looking to do. 

# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011

# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.

# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").

# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.

# Cleaned datatypes in columns one-by-one while exploring the distinct issues across different quarters. We will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, and q3_2018. 

q4_2022 <- read_csv("data/2022Q4.csv") %>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4")) %>%
  rename(start_date = perform_start_dt,
         end_date = perform_end_dt)
  

q3_2022 <- read_csv("data/2022Q3.csv") %>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))


q2_2022 <- read_csv("data/2022Q2.csv") %>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))


q1_2022 <- read_csv("data/2022Q1.csv")%>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column

q4_2021 <- read_csv("data/2021Q4.csv") %>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file 
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""   
#2 27712    14 15 columns      14 columns ""

# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")

q3_2021 <- read_csv("data/2021Q3.csv") %>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))

q2_2021 <- read_csv("data/2021Q2.csv")%>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column

q1_2021 <- read_csv("data/2021Q1.csv")%>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))

q4_2020 <- read_csv("data/2020Q4.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))


q3_2020 <- read_csv("data/2020Q3.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))


q2_2020 <- read_csv("data/2020Q2.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))


q1_2020 <- read_csv("data/2020Q1.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file 
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""   
# 2 121791    16 a double FISC   ""   
# 3 121792    16 a double FISC   ""   
# 4 121793    16 a double FISC   ""   
# 5 132094    16 a double FISC   ""   
# 6 132095    16 a double FISC   ""   
# 7 132096    16 a double FISC   ""   
# 8 132097    16 a double FISC   ""   
# 9 132098    16 a double FISC   ""   
#10 132099    16 a double FISC   ""   
#11 132100    16 a double FISC   ""   
#12 132101    16 a double FISC   ""   
#13 132102    16 a double FISC   ""   
#14 132103    16 a double FISC   ""   
#15 132104    16 a double FISC   ""   
#16 132105    16 a double FISC   ""   
#17 132106    16 a double FISC   ""   
#18 132107    16 a double FISC   ""   
#19 132108    16 a double FISC   ""   
#20 132109    16 a double FISC   ""

# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?


q4_2019 <- read_csv("data/2019Q4.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))


q3_2019 <- read_csv("data/2019Q3.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))


q2_2019 <- read_csv("data/2019Q2.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"

q1_2019 <- read_csv("data/2019Q1.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))


q4_2018 <- read_csv("data/2018Q4.csv")%>%
  mutate(YEAR = as.numeric(2018)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))


q3_2018 <- read_csv("data/2018Q3.csv") %>%
  mutate(YEAR = as.numeric(2018)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file 
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 "" 

# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")

q2_2018 <- read_csv("data/2018Q2.csv")%>%
  mutate(YEAR = as.numeric(2018)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))

q1_2018 <- read_csv("data/2018Q1.csv")%>%
  mutate(YEAR = as.numeric("2018")) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))

```


```{r}

# Bind dataframes into one combined dataframe  

house_spend_18_22 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))

# Number of rows is 2,185,315
 
unique(house_spend_18_22$sort_sequence)

house_spend_18_22 <- house_spend_18_22 %>%
  mutate(office_year = as.numeric(sub(".*?(\\d{4}).*", "\\1", house_spend_18_22$office)))

glimpse(house_spend_18_22)

```

# Bring in ProPublica's Congress API

In this section, we installed the "ppcong" package in order to get information on individual members of the House of Representatives.

```{r}
# Install necessary packages (remove # if libraries are needed)

#remotes::install_github("mkearney/dapr")
#remotes::install_github("mkearney/tfse")
#remotes::install_github("mkearney/ppcong")

# Load ppcong library 

library(ppcong)

## Save API key for use in ppcong. Data in parentheses can be replaced by another individual API key. 

ppc_api_key("yosRYPlksfSYRNTfhgot3bNTzvYQNZ8ztredZ7da", set_renv = TRUE) #this is Aya's api key

# Bring in information on House members for the 115th, 116th and 117th congresses, which cover from January 2017 to January 2023, as our expenditure dataset covers 2018 to 2022.

h115 <- ppc_members(congress = "115", chamber = "house")
h116 <- ppc_members(congress = "116", chamber = "house")
h117 <- ppc_members(congress = "117", chamber = "house")
```

# Bind API dataframes 

We bound the three API datasets that consist of members of the House from the last three Congresses to get one large dataset that consists of all of them. Then, we cleaned the dataset to only include the columns we need, which are id, names, gender, party, state and district.

This dataset included some duplicates due to certain members serving on more than one Congress. To address this, we used the "distinct" function.

Then, we joined our Expenses dataset with the cleaned House members dataset.

```{r}

# Bind dataframes from the three Congresses
members_18_22 <- bind_rows(list(h115, h116, h117))

# Select the columns that we need and then get rid of any duplicates
cleaned_members_18_22 <- members_18_22 |> 
  select(id, first_name, last_name, gender, party, state, district) |> 
  distinct()|> 
  mutate(first_name = str_to_upper(first_name))|>  
  mutate(last_name = str_to_upper(last_name))

```


```{r}
# Join the member information with our expenses dataset using the bioguide id
spend_with_member_info <- house_spend_18_22 |> 
  left_join(cleaned_members_18_22, by = c("bioguide_id" = "id"))

```

Getting a many-to-many issue. Let's try to find the source

```{r}

cleaned_members_18_22 %>%
  group_by(id) %>%
  summarise(instances = n()) %>%
  arrange(desc(instances))

```

Let's check a few examples from the list above to see why there are duplicates

A000367 - Justin Amash switched from R to I which is why he's showing up twice
B001296 - Brendan Boyle switched districts which is why he's showing up twice
C001090 - MATT CARTWRIGHT switched districts which is why he's showing up twice
D000482 - MIKE DOYLE switched districts which is why he's showing up twice

Let's remove districts from the ppcong data before removing dupes. We shouldn't need districts to answer the questions we're pursuing for this project. Hopefully that'll only leave us with Amash showing up twice.


```{r}
recleaned_members_18_22 <- members_18_22 |> 
  select(id, first_name, last_name, gender, party, state) |> 
  distinct()|> 
  mutate(first_name = str_to_upper(first_name))|>  
  mutate(last_name = str_to_upper(last_name))
```


```{r}
recleaned_members_18_22 %>%
  group_by(id) %>%
  summarise(instances = n()) %>%
  arrange(desc(instances))
```

M001201 - PAUL MITCHELL switched from R to I with a few weeks left in his term in Dec 2020
V000133 - JEFFERSON VAN DREW switched from D to R in Jan 2020

Our focus in this project will be on DMV representatives, and (gracefully) Mitchell, Van Drew, and Amash were all from other states. This means we can redo the join now without worrying about the remaining many-to-many issues they're causing since those rows will get filtered out right afterwards

```{r}
# Join the member information with our expenses dataset using the bioguide id
# Also add a step so we're only looking at DMV representatives
dmv_spend_with_member_info <- house_spend_18_22 |> 
  left_join(recleaned_members_18_22, by = c("bioguide_id" = "id")) |>
  filter(state == "DC" | state == "VA" | state == "MD")

# create a dmv_df that's only the subtotals
  
totals_dmv_spend <- dmv_spend_with_member_info %>%
  filter(sort_sequence == "SUBTOTAL") %>%
  select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -payee, -start_date, -end_date, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)

# do the same thing for house_spend_18_22, which we will also use later. 

house_spend_18_22 <- house_spend_18_22 %>%
  filter(sort_sequence == "SUBTOTAL") %>%
  select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -payee, -start_date, -end_date, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)
  
# write the dataframes to csv in order to skip the cleaning process moving forward 

write_csv(totals_dmv_spend, "data/totals_dmv_spend.csv")

write_csv(house_spend_18_22, "data/house_spend_18_22.csv")

```

Data dictionary questions:

"DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011.

  - Confirm "DATE" is filing date - CONFIRMED
  - Why does q4_2019 have expenses that go back all the way to 2011? - SOMETIMES A MEMBER'S OFFICE WILL REALIZE THERE WAS A BOOKEEPING ERROR EVEN FURTHER BACK THAN THE THREE YEAR LIMIT MENTIONED IN THE PROPUBLICA ARTICLE. OTHER TIMES, A VENDOR WILL IDENTIFY A BOOKEEPING ERROR FROM YEARS PRIOR ON THEIR END AND NOTIFY THE MEMBER'S OFFICE ABOUT IT, AND THEN THE MEMBER'S OFFICE WILL UPDATE THEIR BOOKS TOO

YEAR seems to pertain to the filing year rather than the expense year.

  - Confirm? - CONFIRMED


The start and end date cols seem to pertain to the dates of the expenses themselves.

  - Confirm? - CONFIRMED
  
When the amount is negative, what does that signify?

- THIS IS WHEN THE MEMBER'S OFFICE IS REBATED FOR EXPENSES. FOR EXAMPLE, MAYBE THE OFFICE CANCELED A $1MIL CONTRACT WITH A VENDOR AFTER ONLY SPENDING 200K, SO A -800K RECORD WILL APPEAR.

## Deliverable 2:

# Loads and cleans the core data set to prepare for analysis.

- Done (see above)

# Shows basic exploratory analysis to demonstrate an understanding of the dataset, including the number of rows and columns, any obvious limitations or flaws and any reasons why it might not be able to answer the questions you've posed last week.

- Done, see code below. After extensive head scratching, we realize that OFFICIAL EXPENSES OF MEMBERS and INTERN ALLOWANCES were duplicative of the other 9 values in the "purpose" column. These are the 2 values in the "program column" which was a dead giveaway. Overall, this is a frustrating dataset at first blush because you don't know what column is the most accurate representation of what we would generally call a spending category. 


# Describe the limits of the data in terms of timeframe, what is and is not included and any codes or other information you'd need to find definitions for, and what you've done to better define it.

- Because members can report expenses late (in some cases, years later), it's very possible that we don't actually have all of the expenses that occurred during the years we're interested in. The expenditure data for Q1 2023 had an "id" column separate from the bioguide_ID column and it's unclear what that pertains to. We likely don't need it for our analyses though. Better definitions or a data dictionary for columns like "budget object class" and "budget object code" would be helpful, but we might not need that information for our analyses either. We have already done work to better-define the various date columns present in the data (detailed earlier in this notebook) and to understand the records with negative amount values.

##### POST-CLEAN |  START FROM HERE TO SKIP CLEANING PROCESS WITH FRESH DATAFRAME (R WILL RUN FASTER :)) #### 

## Load in cleaned data. 

```{r}

# Read in the data for spending of DMV reps. 

totals_dmv_spend <- read_csv("data/totals_dmv_spend.csv")

# Glimpse the cleaned details data set

glimpse(totals_dmv_spend)

```
## Do some basic aggregates to make sure that further cleaning isn't needed. 

```{r}

# Let's look at the spending categories (column is called purpose) to get a general sense of where reps are using their budgets. 

totals_dmv_spend_purpose <- totals_dmv_spend %>%
  group_by(purpose) %>%
  summarise(total_expenses = sum(amount)) %>%
  arrange(desc(total_expenses))

totals_dmv_spend_purpose 

# OFFICIAL EXPENSES OF MEMBER TOTALS sounds really vague, and it's the top category by far with a spend of $135,333,002.69. We also notice that Official Expenses of Members is one of the two options for the "program" column in totals_dmv_spend. That seems like a red flag. 

# The other value in the program column is INTERN ALLOWANCES. We have a column in totals_dmv_spend_purpose called INTERN ALLOWANCES TOTALS: as well, which totals $1,532,417.41

# Are these two values in the purpose category redundant? Let's save these numbers, then filter the two rows out and see if they equal the sum of all other purposes that remain. 

official <- 135333002.69
interns <- 1532417.41

totals_dmv_spend_purpose <- totals_dmv_spend %>%
  filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|> 
  filter(purpose != "INTERN ALLOWANCES TOTALS:")|> 
  group_by(purpose) %>%
  summarise(total_expenses = sum(amount)) %>%
  arrange(desc(total_expenses))

totals_dmv_spend_purpose 

# What's the sum of all of the remaining 9 categories? Does it equal the sum of OFFICIAL EXPENSES OF MEMBER TOTALS and INTERN ALLOWANCES? 

totals_dmv_spend_purpose |> 
  summarise(total = sum(total_expenses))

without_official_interns <- 136865420	

remainder <- (without_official_interns - official - interns)

remainder

# I am not sure why we have $0.10 left over. Upon manually checking the math for the without_official_interns figure, it was actually #136,865,420.10. So we're good! 

# Let's make this same change in the totals_dmv_spend so that we are permanently excluding these redundancies when working with that dataframe. 

totals_dmv_spend <- totals_dmv_spend %>%
  filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|> 
  filter(purpose != "INTERN ALLOWANCES TOTALS:")

# Just double checking that now we have only the appropriate 9 options for purpose. 

totals_dmv_spend_purpose <- totals_dmv_spend %>%
  group_by(purpose) %>%
  summarise(total_expenses = sum(amount)) %>%
  arrange(desc(total_expenses))

totals_dmv_spend_purpose 

# Let's get a percent of total column as well. 

totals_dmv_spend_purpose <- totals_dmv_spend_purpose |> 
  mutate(pct_of_total = (total_expenses/(sum(total_expenses)))*100)
         
# Looks good! 

```


### Question 1

* **Question**: Do US reps from DC, Maryland and Virginia spend less on average than their colleagues? It seems logical that they would spend significantly less at least on travel, but is that the case? If so, does that mean they spend less overall, or do they outspend their peers in other categories?

* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]

```{r}

# Read back in data for house spend. 

house_spend_18_22 <- read_csv("data/house_spend_18_22.csv")

# Clean it the same way we did for the DMV members. 

house_spend_18_22 <- house_spend_18_22 |> 
  filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|> 
  filter(purpose != "INTERN ALLOWANCES TOTALS:")

house_spend_18_22 

# Calculate avg spend for all members, not just those in the DMV. First, confirm that there are 435 unique members per year

house_spend_18_22 %>%
  filter(office_year >= 2018) %>%
  group_by(office_year, bioguide_id) %>%
  summarise() %>%
  group_by(office_year) %>%
  summarise(count = n())

# Well that's weird. Why is there a member in office year 2023 when we are looking at expenses from 2018-2022? We gotta filter that out. 

house_spend_18_22 %>%
  filter(office_year >= 2018) %>%
  #filter(office_year <= 2022)|> 
  group_by(office_year, bioguide_id) %>%
  summarise() %>%
  group_by(office_year) %>%
  summarise(count = n())


# Surprisingly, there are more than 435 members each year even after we've filtered out records without a bioguide_id. Not sure why that is, but we'll need to divide by the numbers above to find our average rather than 435 for every year. 

house_spend_18_22_totals <- house_spend_18_22 %>%
  group_by(year) %>%
  summarise(annual_total = sum(amount)) %>%
  mutate(members_per_year = c(451, 447, 442, 451, 448)) %>%
  mutate(annual_avg_per_member = annual_total / members_per_year)
  
house_spend_18_22_totals

# Now do the same process for DMV reps. 

totals_dmv_spend %>%
  filter(office_year >= 2018) %>%
  group_by(office_year, bioguide_id) %>%
  summarise() %>%
  group_by(office_year) %>%
  summarise(count = n())

totals_dmv_spend_totals <- totals_dmv_spend %>%
  group_by(year) %>%
  summarise(dmv_annual_total = sum(amount)) %>%
  mutate(dmv_annual_avg_per_member = dmv_annual_total / 20)

totals_dmv_spend_totals

house_dmv_totals <- house_spend_18_22_totals |> 
  left_join(totals_dmv_spend_totals, join_by(year))

house_dmv_totals

house_dmv_totals |> 
  group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|> 
  summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)

house_dmv_totals <- house_dmv_totals |> 
  group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|> 
  summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)

average_total_difference <- mean(house_dmv_totals$difference)

average_total_difference 

# So on average, DMV reps spent less every year than the House as a whole did, on average $17,073.92 less per member each year. Now let's break it out by category to test the hypothesis that they probably spend less on transportation than other members do. 

house_spend_18_22_travel <- house_spend_18_22 %>%
  filter(purpose == "TRAVEL TOTALS:") %>%
  #need to group_by and calculate avgs per year so our avgs aren't skewed based on how many years a member has served
  group_by(year) %>%
  summarise(annual_total = sum(amount)) %>%
  mutate(members_per_year = c(451, 447, 442, 451, 448)) %>%
  mutate(annual_avg_per_member = annual_total / members_per_year)
  
house_spend_18_22_travel

dmv_spend_travel <- totals_dmv_spend %>%
  filter(purpose == "TRAVEL TOTALS:") %>%
  #need to group_by and calculate avgs per year so our avgs aren't skewed based on how many years a member has served
  group_by(year) %>%
  summarise(dmv_annual_total = sum(amount)) %>%
  mutate(dmv_annual_avg_per_member = dmv_annual_total / 20)

dmv_spend_travel

house_dmv_travel <- house_spend_18_22_travel |> 
  left_join(dmv_spend_travel, join_by(year))

house_dmv_travel

house_dmv_travel<- house_dmv_travel |> 
  group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|> 
  summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)

average_difference <- mean(house_dmv_travel$difference)

average_difference

# Hypothesis confirmed that they spend substantially less on travel than other members, on average more $32,870.38 less annually per member. 

```

### Question 2

* **Question**: Which political party in the DMV does the most spending, and does that change with whether or not that party holds the majority in the House?


* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]

```{r}
# First we needed to do a little research about who controlled the House from 2018-2022. It was Republicans in 2018 and Democrats every other year, so we made a simple spreadsheet to import. Let's do that now. 

house_majority <- read_csv("data/house_majority.csv")

# Join with the totals_dmv_spend dataframe 

totals_dmv_spend <- totals_dmv_spend |> 
  left_join(house_majority, join_by("office_year" == "year"))

totals_dmv_spend
```

```{r}
# We want to find the number of members each party had in the DMV each year. This will eventually allow us to calculate an average spend by party for each year

# first, make a df with one row per member per year, along with their party


all_members_per_year <- totals_dmv_spend %>%
  group_by(office_year,bioguide_id,party) %>%
  summarise()

all_members_per_year
```

```{r}
# calculate party members per year

members_grouped_per_year <- all_members_per_year %>%
  group_by(party, office_year) %>%
  summarise(party_members_per_year = n()) %>%
  arrange(office_year)

members_grouped_per_year
```

```{r}
# calculate how much each party spent per year

party_spending_annual <- totals_dmv_spend |>
  group_by(party, office_year, majority_party)|>
  summarise(party_spend = sum(amount))|>
  arrange(desc(party_spend)) %>%
  arrange(office_year)

party_spending_annual
```

```{r}
# join the dfs and calculate an average spend per member for each party per year from 2018 onward

party_spending_w_rep_numbers <- party_spending_annual %>%
  left_join(members_grouped_per_year) %>%
  mutate(avg_spend_per_member = party_spend / party_members_per_year) %>%
  filter(office_year >=2018)  %>%
  arrange(desc(avg_spend_per_member)) 

party_spending_w_rep_numbers
```

### Question 3

* **Question**: Did the most common categories of spending change during COVID? For example, were members spending less on office equipment while everyone was working remotely? Or did they perhaps spend more on franked mail to communicate with constituents during isolation?

* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]


```{r}
# Since there isn't a specific date column, we need to go by year. 2020 and 2021 were the main COVID years.

# We need to look at total spending of each category by year:

category_by_year <- totals_dmv_spend |> 
  group_by(year, category) |> 
  summarize(total_spend = sum(amount)) |> 
  drop_na()

category_by_year

# It's really hard to compare the amounts by just looking at the table. A visualization would greatly help with comparing the different categories:

category_by_year |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  facet_wrap(~category) +
  labs(x="Year",
       y="Amount Spent")

# The scales being the same doesn't work, so separating them is the best way to compare.

category_by_year |> 
  filter(category == "PERSONNEL COMPENSATION") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="PERSONNEL COMPENSATION",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "EQUIPMENT") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="EQUIPMENT",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "FRANKED MAIL") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="FRANKED MAIL",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "OTHER SERVICES") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="OTHER SERVICES",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "PRINTING AND REPRODUCTION") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="PRINTING AND REPRODUCTION",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "RENT  COMMUNICATION  UTILITIES") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="RENT COMMUNICATION UTILITIES",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "SUPPLIES AND MATERIALS") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="SUPPLIES AND MATERIALS",
       caption="source: ProPublica")

category_by_year |> 
  filter(category == "TRAVEL") |> 
  ggplot() +
  geom_line(aes(x=year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="TRAVEL",
       caption="source: ProPublica")

```

### Question 4

* **Question**: Let's get a sense of the high highs and low lows. What are the biggest expenses for DMV reps? Who is the most frugal spender? 


* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]


## What are the highest expenses in the dataset? 

```{r}

# What are the top individual expenses from DMV reps, 2018-2022?

totals_dmv_spend |> 
  group_by(last_name, first_name, purpose, amount)|> 
  arrange(desc(amount))

# We know from totals_dmv_spend_purpose that personnel compensation makes up the lion's share (78%) of spending by Congress. The top expense from DMV Reps between 2018 and 2022 is from Elaine G. Luria, a Democrat from Virginia. In 2022, someone in her office made $573,977.80. HOLY SMOKES. That's a pretty penny and might be a story all by itself. Donald McEachin, another Democrat from VA, also paid a staff member more than half a million dollars last year. I'd guess these would be for Chief of Staff positions, but that needs to be verified. Shame on them! Go work in the private sector if you want to get rich off the backs of the 99%. 

```

## Which offices in the DMV are spending the least annually? There may be an interesting story behind lawmakers who have shown restraint in spending their budgets compared to colleagues.

```{r}

# Create a new column that sums an offices expenses into a total sum.  

spend_by_office <- totals_dmv_spend |> 
  filter(office_year >= 2018) |> 
  group_by(last_name, first_name, office_year)|> 
  summarise(office_total = sum(amount))

# Arrange to see which office spent the least over a year. 

spend_by_office |> 
   arrange(office_total)
 
# Kweisi Mfume spent $729,418.30 in 2020. Way to go, man. 

```

### Question 5

* **Question**: Has staff pay kept on pace with wage growth nation-wide? The Federal Times has reported on this question, but we think it would be well-suited for data visualization.


* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]

```{r}
staff_pay <- totals_dmv_spend |> 
  filter(category == "PERSONNEL COMPENSATION") |> 
  group_by(program, year) |> 
  summarize(congress_average = sum(amount)/n())

standard_staff_pay <- staff_pay |> 
  filter(program != "INTERN ALLOWANCES")

national_wages <- read_csv("data/national_average_wage_index.csv") |> clean_names()

staff_plus_national <- standard_staff_pay |> left_join(national_wages, join_by(year))

staff_plus_national |> 
  ggplot(aes(x = year)) +
  geom_line(aes(y = congress_average), color= "red")+
  geom_line(aes(y = index), color = "blue") +
  labs(x="Year",
       y="Amount Paid",
       title="",
       caption="source: ProPublica") +
  theme_minimal()

```

### Memo 

This story memo should pitch a story idea derived primarily from your analysis of the data, including a discussion of what you found that was newsworthy when you analyzed the data, how the data could be used to develop the story, and what additional steps would be needed to complete the reporting of this story.
The story memo should be written as if you were trying to get the attention of a very busy editor and convince that editor to give you the opportunity to pursue a story you believe is suggested by your analysis.
The final story memo should include the following:
A strong statement at the top. Write this as if I am your editor and you are competing for my attention with reporters pitching other story ideas. That is, don’t start by saying, “I sat down and launched R and looked at the database and sorted it 10 different ways.” Tell me right up front what you found that was interesting or what you found that suggests a dynamite story. Tell me how your most newsworthy findings relate to what you found in your research about prior uses of similar data for stories elsewhere. Do not pitch your findings for more than they are worth, however, or make assertions not supported by your work.
A summary of the results of your analysis. Describe results that are germane to the main thrust of the story you are pitching and, if appropriate, relevant results that suggest other interesting avenues to explore. Indicate whether your findings are new or whether they present a local angle for similar findings reported elsewhere.
Pros and cons of the data. Discuss both the strengths and limitations of the data.
How you would verify your findings. Identify the specific reporting and data steps would you take and the types of information you would use to determine whether the results of your analysis are accurate and significant. If your analysis suggests fault or issues of accountability on the part of public or private figures, indicate whom you would need to contact for response to ensure that your reporting was fair and accurate.
Bringing it home. Indicate the specific steps you would need to take to finish reporting the story. Include the people you would contact and, if relevant, the places you would visit. Indicate how you would make the story real to readers.
Editors are not interested in process. Don’t fill the memo with what steps you took.