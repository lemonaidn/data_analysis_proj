---
title: "Data Anaylisis Team 3 Notebook"
author: "Aidan Hughes, Aya Hussein, Caley Fox Shannon"
date: "`r Sys.Date()`"
output: html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

For our data analysis project, we have chosen to look at House of Representatives Office Expenditures. We think that the dataset is rich with newsworthy details and we know that the public is generally interested in how lawmakers spend our tax dollars.

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}

# Turn off scientific notation. 

options(scipen=999)

# Load libraries. 

library(tidyverse)
library(readr)
library(scales)
library(janitor)

```

### TO SKIP CLEAN PROCESS AND WORK WITH totals_dmv_spend, use search function to look for "POST-CLEAN" and start there.  

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data. 

```{r}

# Load the data from ProPublica.

# In the sort_sequence row, we will ONLY be using "SUBTOTAL" rows, filtering out specific expenses (DETAIL) and GRAND TOTAL FOR ORGANIZATION so that the dataset is small enough to be agile and does not have redundancies that will adversely impact the math we're looking to do. 

# "DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011

# YEAR is not always populated. When it is, it seems to pertain to the filing year rather than the expense year.

# QUARTER is sometimes unpopulated, sometimes populated with a numeric, and sometimes populated with a chr (eg "Q2" instead of just "2").

# DATE col values aren't always populated (within the same df some rows are and some rows aren't). Can't use it to extract quarter and year values.

# Cleaned datatypes in columns one-by-one while exploring the distinct issues across different quarters. We will make this more concise in the near future by using regex and a for loop to iterate across a list of dfs and make the year and quarter updates. We'll then only need to apply additional fixes to q4_2022, q4_2021, and q3_2018. 

q4_2022 <- read_csv("data/2022Q4.csv") %>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4")) %>%
  rename(start_date = perform_start_dt,
         end_date = perform_end_dt)
  

q3_2022 <- read_csv("data/2022Q3.csv") %>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))


q2_2022 <- read_csv("data/2022Q2.csv") %>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))


q1_2022 <- read_csv("data/2022Q1.csv")%>%
  mutate(YEAR = as.numeric(2022)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))
# Need to populate the QUARTER column

q4_2021 <- read_csv("data/2021Q4.csv") %>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))
# parsing errors in row 27712:
# row   col expected        actual     file 
#  <int> <int> <chr>           <chr>      <chr>
#1 27712    12 date in ISO8601 4-Jul-21   ""   
#2 27712    14 15 columns      14 columns ""

# Needed to manually add the value 2021-07-04 to q4_2021[27711,12]
q4_2021[27711,12] = as.Date("2021-07-04")

q3_2021 <- read_csv("data/2021Q3.csv") %>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))

q2_2021 <- read_csv("data/2021Q2.csv")%>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))
# Need to populate the QUARTER column

q1_2021 <- read_csv("data/2021Q1.csv")%>%
  mutate(YEAR = as.numeric(2021)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))

q4_2020 <- read_csv("data/2020Q4.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))


q3_2020 <- read_csv("data/2020Q3.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))


q2_2020 <- read_csv("data/2020Q2.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))


q1_2020 <- read_csv("data/2020Q1.csv")%>%
  mutate(YEAR = as.numeric(2020)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))
# parsing errors in :
#      row   col expected actual file 
#    <int> <int> <chr>    <chr>  <chr>
# 1 121790    16 a double FISC   ""   
# 2 121791    16 a double FISC   ""   
# 3 121792    16 a double FISC   ""   
# 4 121793    16 a double FISC   ""   
# 5 132094    16 a double FISC   ""   
# 6 132095    16 a double FISC   ""   
# 7 132096    16 a double FISC   ""   
# 8 132097    16 a double FISC   ""   
# 9 132098    16 a double FISC   ""   
#10 132099    16 a double FISC   ""   
#11 132100    16 a double FISC   ""   
#12 132101    16 a double FISC   ""   
#13 132102    16 a double FISC   ""   
#14 132103    16 a double FISC   ""   
#15 132104    16 a double FISC   ""   
#16 132105    16 a double FISC   ""   
#17 132106    16 a double FISC   ""   
#18 132107    16 a double FISC   ""   
#19 132108    16 a double FISC   ""   
#20 132109    16 a double FISC   ""

# The parsing issue is that "FISC" is showing up in 20 rows in the YEAR column. R has changed those values to NULL by default.
# No further action required on the parsing issue
# what does the id column here refer to since there's also already a bioguide_id?


q4_2019 <- read_csv("data/2019Q4.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))


q3_2019 <- read_csv("data/2019Q3.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))


q2_2019 <- read_csv("data/2019Q2.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))
# QUARTER col is in format "Q2" rather than just "2"

q1_2019 <- read_csv("data/2019Q1.csv")%>%
  mutate(YEAR = as.numeric(2019)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))


q4_2018 <- read_csv("data/2018Q4.csv")%>%
  mutate(YEAR = as.numeric(2018)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("4"))


q3_2018 <- read_csv("data/2018Q3.csv") %>%
  mutate(YEAR = as.numeric(2018)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("3"))
# Parsing issues:
#    row   col expected        actual      file 
#  <int> <int> <chr>           <chr>       <chr>
# 1 90121    11 date in ISO8601 22-AUG-1818 "" 

# Need to manually update q3_2018[90120, 11] to 2018-08-22
q3_2018[90120, 11] = as.Date("2018-08-22")

q2_2018 <- read_csv("data/2018Q2.csv")%>%
  mutate(YEAR = as.numeric(2018)) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("2"))

q1_2018 <- read_csv("data/2018Q1.csv")%>%
  mutate(YEAR = as.numeric("2018")) %>%
  clean_names() %>%
  mutate(quarter = as.numeric("1"))

```


```{r}

# Bind dataframes into one combined dataframe  

house_spend_18_22 <- bind_rows(list(q4_2022, q3_2022, q2_2022, q1_2022, q4_2021, q3_2021, q2_2021, q1_2021, q4_2020, q3_2020, q2_2020, q1_2020, q4_2019, q3_2019, q2_2019, q1_2019, q4_2018, q3_2018, q2_2018, q1_2018))

# Number of rows is 2,185,315
 
unique(house_spend_18_22$sort_sequence)

house_spend_18_22 <- house_spend_18_22 %>%
  mutate(office_year = as.numeric(sub(".*?(\\d{4}).*", "\\1", house_spend_18_22$office)))

glimpse(house_spend_18_22)

```

# Bring in ProPublica's Congress API

In this section, we installed the "ppcong" package in order to get information on individual members of the House of Representatives.

```{r}
# Install necessary packages (remove # if libraries are needed)

#remotes::install_github("mkearney/dapr")
#remotes::install_github("mkearney/tfse")
#remotes::install_github("mkearney/ppcong")

# Load ppcong library 

library(ppcong)

## Save API key for use in ppcong. Data in parentheses can be replaced by another individual API key. 

ppc_api_key("yosRYPlksfSYRNTfhgot3bNTzvYQNZ8ztredZ7da", set_renv = TRUE) #this is Aya's api key

# Bring in information on House members for the 115th, 116th and 117th congresses, which cover from January 2017 to January 2023, as our expenditure dataset covers 2018 to 2022.

h115 <- ppc_members(congress = "115", chamber = "house")
h116 <- ppc_members(congress = "116", chamber = "house")
h117 <- ppc_members(congress = "117", chamber = "house")
```

# Bind API dataframes 

We bound the three API datasets that consist of members of the House from the last three Congresses to get one large dataset that consists of all of them. Then, we cleaned the dataset to only include the columns we need, which are id, names, gender, party, state and district.

This dataset included some duplicates due to certain members serving on more than one Congress. To address this, we used the "distinct" function.

Then, we joined our Expenses dataset with the cleaned House members dataset.

```{r}

# Bind dataframes from the three Congresses
members_18_22 <- bind_rows(list(h115, h116, h117))

# Select the columns that we need and then get rid of any duplicates
cleaned_members_18_22 <- members_18_22 |> 
  select(id, first_name, last_name, gender, party, state, district) |> 
  distinct()|> 
  mutate(first_name = str_to_upper(first_name))|>  
  mutate(last_name = str_to_upper(last_name))

```


```{r}
# Join the member information with our expenses dataset using the bioguide id
spend_with_member_info <- house_spend_18_22 |> 
  left_join(cleaned_members_18_22, by = c("bioguide_id" = "id"))

```

Getting a many-to-many issue. Let's try to find the source

```{r}

cleaned_members_18_22 %>%
  group_by(id) %>%
  summarise(instances = n()) %>%
  arrange(desc(instances))

```

Let's check a few examples from the list above to see why there are duplicates

A000367 - Justin Amash switched from R to I which is why he's showing up twice
B001296 - Brendan Boyle switched districts which is why he's showing up twice
C001090 - MATT CARTWRIGHT switched districts which is why he's showing up twice
D000482 - MIKE DOYLE switched districts which is why he's showing up twice

Let's remove districts from the ppcong data before removing dupes. We shouldn't need districts to answer the questions we're pursuing for this project. Hopefully that'll only leave us with Amash showing up twice.


```{r}
recleaned_members_18_22 <- members_18_22 |> 
  select(id, first_name, last_name, gender, party, state) |> 
  distinct()|> 
  mutate(first_name = str_to_upper(first_name))|>  
  mutate(last_name = str_to_upper(last_name))
```


```{r}
recleaned_members_18_22 %>%
  group_by(id) %>%
  summarise(instances = n()) %>%
  arrange(desc(instances))
```

M001201 - PAUL MITCHELL switched from R to I with a few weeks left in his term in Dec 2020
V000133 - JEFFERSON VAN DREW switched from D to R in Jan 2020

Our focus in this project will be on DMV representatives, and (gracefully) Mitchell, Van Drew, and Amash were all from other states. This means we can redo the join now without worrying about the remaining many-to-many issues they're causing since those rows will get filtered out right afterwards

```{r}
# Join the member information with our expenses data set using the bioguide id
# Also add a step so we're only looking at DMV representatives
dmv_spend_with_member_info <- house_spend_18_22 |> 
  left_join(recleaned_members_18_22, by = c("bioguide_id" = "id")) |>
  filter(state == "DC" | state == "VA" | state == "MD")

# create a dmv_df that's only the subtotals
  
totals_dmv_spend <- dmv_spend_with_member_info %>%
  filter(sort_sequence == "SUBTOTAL") %>%
  select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -payee, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)

# do the same thing for house_spend_18_22, which we will also use later. 

house_spend_18_22 <- house_spend_18_22 %>%
  filter(sort_sequence == "SUBTOTAL") %>%
  select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -payee, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)
  
# write the dataframes to csv in order to skip the cleaning process moving forward 

write_csv(totals_dmv_spend, "data/totals_dmv_spend.csv")

write_csv(house_spend_18_22, "data/house_spend_18_22.csv")

```

Data dictionary questions:

"DATE" column seems to pertain to the date the expense was filed, whereas the start and end date cols seem to pertain to the dates of the expenses themselves. for example, q4_2019 has expenses that go back all the way to 2011.

  - Confirm "DATE" is filing date - CONFIRMED
  - Why does q4_2019 have expenses that go back all the way to 2011? - SOMETIMES A MEMBER'S OFFICE WILL REALIZE THERE WAS A BOOKEEPING ERROR EVEN FURTHER BACK THAN THE THREE YEAR LIMIT MENTIONED IN THE PROPUBLICA ARTICLE. OTHER TIMES, A VENDOR WILL IDENTIFY A BOOKEEPING ERROR FROM YEARS PRIOR ON THEIR END AND NOTIFY THE MEMBER'S OFFICE ABOUT IT, AND THEN THE MEMBER'S OFFICE WILL UPDATE THEIR BOOKS TOO

YEAR seems to pertain to the filing year rather than the expense year.

  - Confirm? - CONFIRMED


The start and end date cols seem to pertain to the dates of the expenses themselves.

  - Confirm? - CONFIRMED
  
When the amount is negative, what does that signify?

- THIS IS WHEN THE MEMBER'S OFFICE IS REBATED FOR EXPENSES. FOR EXAMPLE, MAYBE THE OFFICE CANCELED A $1MIL CONTRACT WITH A VENDOR AFTER ONLY SPENDING 200K, SO A -800K RECORD WILL APPEAR.

## Deliverable 2:

# Loads and cleans the core data set to prepare for analysis.

- Done (see above)

# Shows basic exploratory analysis to demonstrate an understanding of the dataset, including the number of rows and columns, any obvious limitations or flaws and any reasons why it might not be able to answer the questions you've posed last week.

- Done, see code below. After extensive head scratching, we realize that OFFICIAL EXPENSES OF MEMBERS and INTERN ALLOWANCES were duplicative of the other 9 values in the "purpose" column. These are the 2 values in the "program column" which was a dead giveaway. Overall, this is a frustrating dataset at first blush because you don't know what column is the most accurate representation of what we would generally call a spending category. 


# Describe the limits of the data in terms of timeframe, what is and is not included and any codes or other information you'd need to find definitions for, and what you've done to better define it.

- Because members can report expenses late (in some cases, years later), it's very possible that we don't actually have all of the expenses that occurred during the years we're interested in. The expenditure data for Q1 2023 had an "id" column separate from the bioguide_ID column and it's unclear what that pertains to. We likely don't need it for our analyses though. Better definitions or a data dictionary for columns like "budget object class" and "budget object code" would be helpful, but we might not need that information for our analyses either. We have already done work to better-define the various date columns present in the data (detailed earlier in this notebook) and to understand the records with negative amount values.

##### POST-CLEAN |  START FROM HERE TO SKIP CLEANING PROCESS WITH FRESH DATAFRAME (R WILL RUN FASTER :)) #### 

## Load in cleaned data. 

```{r}

# Read in the data for spending of DMV reps. 

totals_dmv_spend <- read_csv("data/totals_dmv_spend.csv")

# Glimpse the cleaned details data set

glimpse(totals_dmv_spend)

```
## Do some basic aggregates to make sure that further cleaning isn't needed. 

```{r}

# Let's look at the spending categories (column is called purpose) to get a general sense of where reps are using their budgets. 

totals_dmv_spend_purpose <- totals_dmv_spend %>%
  group_by(purpose) %>%
  summarise(total_expenses = sum(amount)) %>%
  arrange(desc(total_expenses))

totals_dmv_spend_purpose 

# OFFICIAL EXPENSES OF MEMBER TOTALS sounds really vague, and it's the top category by far with a spend of $135,333,002.69. We also notice that Official Expenses of Members is one of the two options for the "program" column in totals_dmv_spend. That seems like a red flag. 

# The other value in the program column is INTERN ALLOWANCES. We have a column in totals_dmv_spend_purpose called INTERN ALLOWANCES TOTALS: as well, which totals $1,532,417.41

# Are these two values in the purpose category redundant? Let's save these numbers, then filter the two rows out and see if they equal the sum of all other purposes that remain. 

official <- 135333002.69
interns <- 1532417.41

totals_dmv_spend_purpose <- totals_dmv_spend %>%
  filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|> 
  filter(purpose != "INTERN ALLOWANCES TOTALS:")|> 
  group_by(purpose) %>%
  summarise(total_expenses = sum(amount)) %>%
  arrange(desc(total_expenses))

totals_dmv_spend_purpose 

# What's the sum of all of the remaining 9 categories? Does it equal the sum of OFFICIAL EXPENSES OF MEMBER TOTALS and INTERN ALLOWANCES? 

totals_dmv_spend_purpose |> 
  summarise(total = sum(total_expenses))

without_official_interns <- 136865420	

remainder <- (without_official_interns - official - interns)

remainder

# I am not sure why we have $0.10 left over. Upon manually checking the math for the without_official_interns figure, it was actually #136,865,420.10. So we're good! 

# Let's make this same change in the totals_dmv_spend so that we are permanently excluding these redundancies when working with that dataframe. 

totals_dmv_spend <- totals_dmv_spend %>%
  filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|> 
  filter(purpose != "INTERN ALLOWANCES TOTALS:")

# Just double checking that now we have only the appropriate 9 options for purpose. 

totals_dmv_spend_purpose <- totals_dmv_spend %>%
  group_by(purpose) %>%
  summarise(total_expenses = sum(amount)) %>%
  arrange(desc(total_expenses))

totals_dmv_spend_purpose 

# Let's get a percent of total column as well. 

totals_dmv_spend_purpose <- totals_dmv_spend_purpose |> 
  mutate(pct_of_total = (total_expenses/(sum(total_expenses)))*100)
         
# Looks good! 

```


### Question 1

* **Question**: Do US reps from DC, Maryland and Virginia spend less on average than their colleagues? It seems logical that they would spend significantly less at least on travel, but is that the case? If so, does that mean they spend less overall, or do they outspend their peers in other categories?

* **Analysis summary**: We found that compared to the average in Congress, reps from the DMV spend $15,254.09 less per member each year. We also looked at their travel spending, and found that they spent on average $32,870.38 less annually per year. That means they probably outspend their peers in some other categories, but at least they spend less overall as we expected. 


```{r}
# Read back in data for house spend. 

house_spend_18_22 <- read_csv("data/house_spend_18_22.csv")

# Clean it the same way we did for the DMV members. 

house_spend_18_22 <- house_spend_18_22 |> 
  filter(purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS:")|> 
  filter(purpose != "INTERN ALLOWANCES TOTALS:")

house_spend_18_22 
```


```{r}
# Calculate avg spend for all members, not just those in the DMV. First, confirm that there are 435 unique members per year

house_spend_18_22 <- house_spend_18_22 %>%
  filter(!is.na(bioguide_id))

house_spend_18_22 %>%
  filter(office_year >= 2018) %>%
  group_by(office_year, bioguide_id) %>%
  summarise() %>%
  group_by(office_year) %>%
  summarise(count = n())

# Surprisingly, there are more than 435 members each year even after we've filtered out records without a bioguide_id. Not sure why that is, but we'll need to divide by the numbers above to find our average rather than 435 for every year. 

house_spend_18_22_totals <- house_spend_18_22 %>%
  group_by(year) %>%
  summarise(annual_total = sum(amount)) %>%
  mutate(members_per_year = c(451, 447, 442, 451, 448)) %>%
  mutate(annual_avg_per_member = annual_total / members_per_year)

house_spend_18_22_totals 
  
```

```{r}
# Now do the same process for DMV reps. 

totals_dmv_spend %>%
  filter(office_year >= 2018) %>%
  group_by(office_year, bioguide_id) %>%
  summarise() %>%
  group_by(office_year) %>%
  summarise(count = n())

totals_dmv_spend_totals <- totals_dmv_spend %>%
  group_by(year) %>%
  summarise(dmv_annual_total = sum(amount)) %>%
  mutate(dmv_annual_avg_per_member = dmv_annual_total / 20)

totals_dmv_spend_totals

```

```{r}
# Now join to compare side by side. 

house_dmv_totals <- house_spend_18_22_totals |> 
  left_join(totals_dmv_spend_totals, join_by(year))

house_dmv_totals

house_dmv_totals <- house_dmv_totals |> 
  group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|> 
  summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)

average_total_difference <- mean(house_dmv_totals$difference)

average_total_difference 

# So on average, DMV reps spent less every year than the House as a whole did, on average $15,254.09 less per member each year. 
```


```{r}

# Now let's test the hypothesis that DMV REPS probably spend less on transportation than other members do. 

house_spend_18_22_travel <- house_spend_18_22 %>%
  filter(purpose == "TRAVEL TOTALS:") %>%
  #need to group_by and calculate avgs per year so our avgs aren't skewed based on how many years a member has served
  group_by(year) %>%
  summarise(annual_total = sum(amount)) %>%
  mutate(members_per_year = c(451, 447, 442, 451, 448)) %>%
  mutate(annual_avg_per_member = annual_total / members_per_year)
  
house_spend_18_22_travel

dmv_spend_travel <- totals_dmv_spend %>%
  filter(purpose == "TRAVEL TOTALS:") %>%
  #need to group_by and calculate avgs per year so our avgs aren't skewed based on how many years a member has served
  group_by(year) %>%
  summarise(dmv_annual_total = sum(amount)) %>%
  mutate(dmv_annual_avg_per_member = dmv_annual_total / 20)

dmv_spend_travel

house_dmv_travel <- house_spend_18_22_travel |> 
  left_join(dmv_spend_travel, join_by(year))

house_dmv_travel

house_dmv_travel<- house_dmv_travel |> 
  group_by(year, annual_avg_per_member, dmv_annual_avg_per_member)|> 
  summarise(difference = annual_avg_per_member - dmv_annual_avg_per_member)

house_dmv_travel

average_difference <- mean(house_dmv_travel$difference)

average_difference

# Hypothesis confirmed that they spend substantially less on travel than other members, on average more $32,870.38 less annually per member. But they only spend ~$15.2K less than others overall, meaning that they are overspending somewhere else. 

```

### Question 2

* **Question**: Which political party in the DMV does the most spending, and does that change with whether or not that party holds the majority in the House?


* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]

```{r}
# First we needed to do a little research about who controlled the House from 2018-2022. It was Republicans in 2018 and Democrats every other year, so we made a simple spreadsheet to import. Let's do that now. 

house_majority <- read_csv("data/house_majority.csv")

# Join with the totals_dmv_spend dataframe 

totals_dmv_spend <- totals_dmv_spend |> 
  left_join(house_majority, join_by("office_year" == "year"))

totals_dmv_spend
```

```{r}
# We want to find the number of members each party had in the DMV each year. This will eventually allow us to calculate an average spend by party for each year

# first, make a df with one row per member per year, along with their party


all_members_per_year <- totals_dmv_spend %>%
  group_by(office_year,bioguide_id,party) %>%
  summarise()

all_members_per_year
```

```{r}
# calculate party members per year

members_grouped_per_year <- all_members_per_year %>%
  group_by(party, office_year) %>%
  summarise(party_members_per_year = n()) %>%
  arrange(office_year)

members_grouped_per_year
```

```{r}
# calculate how much each party spent per year

party_spending_annual <- totals_dmv_spend |>
  group_by(party, office_year, majority_party)|>
  summarise(party_spend = sum(amount))|>
  arrange(desc(party_spend)) %>%
  arrange(office_year)

party_spending_annual
```

```{r}
# join the dfs and calculate an average spend per member for each party per year from 2018 onward

party_spending_w_rep_numbers <- party_spending_annual %>%
  left_join(members_grouped_per_year) %>%
  mutate(avg_spend_per_member = party_spend / party_members_per_year) %>%
  filter(office_year >=2018)  %>%
  arrange(desc(avg_spend_per_member)) 

party_spending_w_rep_numbers
```

### Question 3

* **Question**: Did the most common categories of spending change during COVID? For example, were members spending less on office equipment while everyone was working remotely? Or did they perhaps spend more on franked mail to communicate with constituents during isolation?

* **Analysis summary**: We found that during the height of the pandemic in 2020, DMV representatives spent way less on travel and rent, communication utilities. Spending on supplies and materials peaked in 2020, while franked mail was high in 2018, 2020 and 2022 (could be related to them being election years). Spending on printing and reproduction, as well as personnel compensation have all been rising every year. On the other had, spending on equipment has dropped dramatically.


```{r}
# Since there isn't a specific date column, we need to go by year. 2020 and 2021 were the main COVID years.

# We need to look at total spending of each category by year:

category_by_year <- totals_dmv_spend |> 
  filter(office_year >= 2018, office_year <= 2022)|> 
  group_by(office_year, purpose) |> 
  summarize(total_spend = sum(amount)) |> 
  drop_na()

category_by_year

# It's really hard to compare the amounts by just looking at the table. A visualization would greatly help with comparing the different categories:

category_by_year |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  facet_wrap(~purpose) +
  labs(x="Year",
       y="Amount Spent")

# The scales being the same doesn't work, so separating them is the best way to compare.

category_by_year |> 
  filter(purpose == "PERSONNEL COMPENSATION TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="PERSONNEL COMPENSATION",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "EQUIPMENT TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="EQUIPMENT",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "FRANKED MAIL TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="FRANKED MAIL",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "OTHER SERVICES TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="OTHER SERVICES",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "PRINTING AND REPRODUCTION TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="PRINTING AND REPRODUCTION",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "RENT  COMMUNICATION  UTILITIES TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="RENT COMMUNICATION UTILITIES",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "SUPPLIES AND MATERIALS TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="SUPPLIES AND MATERIALS",
       caption="source: ProPublica")

category_by_year |> 
  filter(purpose == "TRAVEL TOTALS:") |> 
  ggplot() +
  geom_line(aes(x=office_year, y=total_spend))+
  labs(x="Year",
       y="Amount Spent",
       title="TRAVEL",
       caption="source: ProPublica")

# Maybe an overlay of all of the above in Datawrapper would be the best way to look at this. We will explore that for the next milestone.


```

### Question 4

* **Question**: Let's get a sense of the high highs and low lows. What are the biggest expenses for DMV reps? Who is the most frugal spender? 


* **Analysis summary**: We know from totals_dmv_spend_purpose that personnel compensation makes up the lion's share (78%) of spending by Congress. The top expense from DMV Reps between 2018 and 2022 is from Elaine G. Luria, a Democrat from Virginia. In 2022, her staffers made at a total of $573,977.80. 

As for the lowest annual spender in the DMV, it appears at first blush to be Kweisi Mfume of Maryland, who spent $729,418.30 in 2020. That's basically a quarter million less than even the next lowest annual spend, which was Donald Beyer's $986,166.50 in 2018. But wait! A Google search tells us that Mfume was sworn in on May 5, 2020, after a special election for the seat of the late Rep. Elijah Cummings. So the honor in fact goes to Rep Don Beyer of Virginia after all. 

## What are the highest expenses in the dataset? 

```{r}

# What are the top individual expenses from DMV reps, 2018-2022?

totals_dmv_spend |> 
  group_by(last_name, first_name, purpose, amount)|> 
  arrange(desc(amount))

```

## Which offices in the DMV are spending the least annually? There may be an interesting story behind lawmakers who have shown restraint in spending their budgets compared to colleagues.

```{r}

# Create a new column that sums an offices expenses into a total sum.  

spend_by_office <- totals_dmv_spend |> 
  filter(office_year >= 2018) |> 
  group_by(last_name, first_name, office_year)|> 
  summarise(office_total = sum(amount))

# Arrange to see which office spent the least over a year. 

spend_by_office |> 
   arrange(office_total)
 


```

### Question 5

* **Question**: Has staff pay kept on pace with wage growth nation-wide? The Federal Times has reported on this question, but we think it would be well-suited for data visualization.

```{r}

details_dmv_staff_pay <- dmv_spend_with_member_info %>%
  filter(category == "PERSONNEL COMPENSATION") %>%
  filter(office_year >= 2018) %>%
  # exclude interns, temporary and part-time employees, and total/subtotal rows 
  filter(program != "INTERN ALLOWANCES") %>%
  filter(purpose != "PERSONNEL COMPENSATION TOTALS:" & purpose != "TEMPORARY EMPLOYEE" & purpose != "PAID INTERN" & purpose != "PART-TIME EMPLOYEE (OTHER COMPENSATION)" & purpose != "PART-TIME EMPLOYEE (OTHER COMPENSATION)" & purpose != "PART-TIME EMPLOYEE" & purpose != "OFFICE TOTALS:" & purpose != "OFFICIAL EXPENSES OF MEMBERS TOTALS") %>%
  select(-organization_code, -program_code, -budget_object_class, -data_source, -document, -vendor_id, -budget_object_code, -transcode, -recordid, -id, -sort_subtotal_description, -transaction_date, -date)

details_dmv_staff_pay

```

Here's where we run into an issue: each of these rows might pertain to different lengths of time, making direct comparison of various amounts (or incorporation into a reliable average) a bit difficult. For example, there's a staff assistant's record that only pertains to 2022-05-02 through 2022-06-30, while other records pertain to the full Q2. This could be for a variety of reasons -- hires or resignations mid-quarter, staff moving from the "official" side to the "campaign" side during an election year, etc.

This is a significant limitation on our ability to easily answer this question using this data set that we didn't recognize earlier.

Although it's not a perfect solution, let's standardize the "amount" values by using the start date and end date of each expense to calculate how many days of a staffer's salary the expense covers. We'll then divide the "amount" col by that number of days, and then multiply it by 91.25 (365/4). These numbers won't be 100% accurate vs their real salaries, but should get us within spitting distance and serve as a pretty rough estimate of what their quarterly (and then annual) salary would be.

```{r}

details_dmv_staff_pay <- details_dmv_staff_pay %>%
  mutate(days_covered = as.numeric(difftime(end_date, start_date, units = "days"))+1) %>%
  mutate(est_quarterly_pay = amount / days_covered * 91.25) %>%
  mutate(est_annual_pay = est_quarterly_pay * 4)


details_dmv_staff_pay

```

Now let's calculate a per-role, per-year avg salary. NOTE: "Other compensation" records seem to be one-time additional payments (do congressional staffers earn bonuses?...) rather than a normal part of staffers' salaries so I'm excluding them. Same with overtime pay.

```{r}

cleaned_details_dmv_staff_pay <- details_dmv_staff_pay %>%
  filter(!str_detect(purpose, "OTHER COMPENSATION") & !str_detect(purpose, "OVERTIME")) %>%
  select(office_year, payee, purpose, est_annual_pay) %>%
  distinct() %>%
  group_by(office_year, purpose) %>%
  summarise(avg_salary = sum(est_annual_pay) / n()) %>%
  arrange(avg_salary)

cleaned_details_dmv_staff_pay

```

It's hard to identify which records or job titles are permanent staff positions vs temporary, contract, etc. expenses without manually checking each of the hundreds of grouped values in the "purpose" column, seeing which dates and frequencies they appear, and then using best judgement/assumptions to further standardize or filter. We weren't feeling confident in the likelihood that the results would be accurate due to all of the factors discussed above.

Let's select and plot just a few roles' averages against national wage growth data just for comparison's sake. However, note that these results are also fuzzy/difficult to use since some job titles suggest dual roles for certain staffers (for example, some schedulers might just be schedulers, while others are both schedulers/press assistant or schedulers/deputy comm dirs, etc.)

```{r}

# get a df with avg annual pay for leg aides, press secs, and schedulers (for job titles ONLY described as schedulers, none with dual roles)

cleaned_details_dmv_staff_pay <- cleaned_details_dmv_staff_pay %>%
  filter(purpose == "SCHEDULER" | purpose == "LEGISLATIVE AIDE" | purpose == "PRESS SECRETARY") %>%
  rename("job_title" = "purpose",
         "year" = "office_year") %>%
  arrange(year)

cleaned_details_dmv_staff_pay

```

```{r}
# update the national_wage df to allow for binding and plotting with the staff pay df from above

national_wages <- read_csv("data/national_average_wage_index.csv") |> clean_names() %>%
  rename("avg_salary" = "index") %>%
  mutate(job_title = "national_wages") %>%
  select(year, job_title, avg_salary) %>%
  filter(year >= 2018)

national_wages 
```

```{r}
wage_comparison_df <- rbind(cleaned_details_dmv_staff_pay, national_wages) %>%
  arrange(year)

wage_comparison_df
```

```{r}
ggplot(wage_comparison_df, aes(x = year, y = avg_salary, color = job_title)) +
  geom_line() +
  geom_point() +
  labs(title = "Leg. aide wages remain far behind national average",
       x = "Year",
       y = "Average Salary",
       color = "Job Title") +
  theme_minimal()
```

(I'll update "national_wages" later so it has a label that matches the format of the other job titles)

Let's try to switch gears and just look at a percent change in staff salaries year over year using subtotal records, and compare that to national trends in wage growth. However, the accuracy of those calculations would rely on a big assumption that the level of staffing has stayed constant and offices have not grown or shrunk year-to-year.

```{r}
# calculate annual % change in personnel expenditures for DMV reps

totals_dmv_spend_pct_change <- totals_dmv_spend %>%
  filter(purpose == "PERSONNEL COMPENSATION TOTALS:",
         program == "OFFICIAL EXPENSES OF MEMBERS") %>%
  group_by(year) %>%
  summarise(amount = sum(amount)) %>%
  # I got ChatGPT's help with this last step since I wasn't familiar with the "lag" function:
  mutate(pct_change = (amount - 18276024) / 18276024 * 100) %>%
  mutate(data_source = "Personnel Expenditure Subtotals")

totals_dmv_spend_pct_change
```

```{r}
# calculate annual % change in personnel expenditures for national wage avgs

national_wages_pct_change <- national_wages %>%
  mutate(pct_change = (avg_salary - 52145.80) / 52145.80 * 100) %>%
  mutate(data_source = "National Wage Avgs") %>%
  rename("amount" = "avg_salary") %>%
  select(-job_title)

national_wages_pct_change
```



```{r}
# bind the data

wage_comparison_pct_change_df <- rbind(totals_dmv_spend_pct_change, national_wages_pct_change) %>%
  arrange(year)

wage_comparison_pct_change_df
```
```{r}
# visualize

ggplot(wage_comparison_pct_change_df, aes(x = year, y = pct_change, color = data_source, group = data_source)) +
  geom_line() +
  geom_point() +
  labs(title = "Growth in House Staff Pay Outpaces National Trends",
       x = "Year",
       y = "Percent Change vs 2018",
       color = "") +
  theme_minimal()

# Display the plot
print(ggplot())
```

### Memo as of Saturday December 2nd. 

Hey Derek! We've been having a time with this data set. It is really complex, with a lot of columns that appear to say very similar things. We have had to do extensive cleaning and filtering beyond that to have a data set that is accurate enough to answer questions but small/concise enough to be manageable and run code quickly. We hit some real snags as well around trying to group by dates, since at a certain point it hit us that an office may change hands when a new rep is sworn in in late January. That lead to the creation of a column called office_year which was extracted from the name of the office, and we're using that value to determine the legislative year of the expense. Not all rows (eg the subtotal rows) have start and end date values populated which is why we couldn't extract year from those cols instead, and most years don't have a pre-defined leg year column already.

We're also struggling right now with figuring out the average compensation for congressional staffers. Not every staffer was paid throughout the duration of an office year. For example, there's a staff assistant's record that only pertains to 2022-05-02 through 2022-06-30, while other records pertain to a full quarter. This could be for a variety of reasons -- hires or resignations mid-quarter, staff moving from the "official" side to the "campaign" side during an election year, etc.

We tried to account for this by standardizing the "amount" values. We used the start date and end date of each expense to calculate how many days of a staffer's salary the expense covers. We then divided the "amount" col by that number of days, and then multiplied it by 91.25 (365/4). Those numbers won't be 100% accurate vs their real salaries, but we hoped would get us within spitting distance and serve as a pretty rough estimate of what their quarterly (and then annual) salary would be.

However, trying to calculate averages for staffers using detail-level data still presented several challenges. Chief among them: it's hard to identify which records or job titles are permanent staff positions vs temporary, contract, etc. expenses without manually checking each of the hundreds of grouped values in the "purpose" column, seeing which dates and frequencies they appear, and then using best judgement/assumptions to further standardize or filter. We weren't feeling confident in the likelihood that the results would be accurate due to all of the factors above.

As an alternate method, we thought about just looking at a percent change in staff salaries year over year and comparing that to national trends in wage growth. However, that would rely on a big assumption that the level of staffing has stayed constant and offices have not grown or shrunk year-to-year.

After doing further reading, even the Congressional Research Service has highlighted the difficulty and data concerns they ran into when trying to use publicly available data to perform similar calculations to ours. They ultimately had to rely on LegiStorm data, and even then listed quite a number of "data concerns" that likely affect the accuracy of their own findings. Here's the report: https://crsreports.congress.gov/product/pdf/R/R44323

Amidst all the chaos, we were still able to find out some pretty interesting trends. One is that when we were comparing spending among DMV representatives during COVID to other years, we found that travel went down, but supplies and materials increased. Printing and reproduction increased dramatically post-COVID, particularly in 2022, where there was a huge spike. We don't have complete 2023 data, but if we did, it would be interesting to see if that category is still rising at the same rate. Franked mail goes up and down every year, going up specifically in 2018, 2020 and 2022. We think this may have something to do with those being election years.

We were also shocked to see that Maryland Rep. Kweisi Mfume spent so little in 2020, with only $729,418.30 in 2020, however we came to find out that he was swore in in May as the replacement for Rep. Cummings who passed away the year before. So the actual lowest annual spender is Rep. Don Beyer with $986,166.50 in 2018.

Overall, this is a real pain to deal with. It's almost like Congress wants us to stay out of it! 